\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\newlabel{tocindent-1}{0pt}
\newlabel{tocindent0}{0pt}
\newlabel{tocindent1}{0pt}
\newlabel{tocindent2}{0pt}
\newlabel{tocindent3}{0pt}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:exp_i_storage}{{1a}{1}{Total storage size\relax }{figure.caption.1}{}}
\newlabel{sub@fig:exp_i_storage}{{a}{1}{Total storage size\relax }{figure.caption.1}{}}
\newlabel{fig:exp_i_save}{{1b}{1}{Average overhead saving time\relax }{figure.caption.1}{}}
\newlabel{sub@fig:exp_i_save}{{b}{1}{Average overhead saving time\relax }{figure.caption.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \textsf  {Chipmink}\xspace  compactly and quickly stores all variables, 5.7--25.5$\times $ smaller and 1.2--7.4$\times $ faster than the best baselines.\relax }}{1}{figure.caption.1}\protected@file@percent }
\newlabel{fig:exp_i}{{1}{1}{\pga compactly and quickly stores all variables, 5.7--25.5$\times $ smaller and 1.2--7.4$\times $ faster than the best baselines.\relax }{figure.caption.1}{}}
\newlabel{fig:exp_iv_ecdf_betterxb}{{2a}{1}{\betterxb \relax }{figure.caption.2}{}}
\newlabel{sub@fig:exp_iv_ecdf_betterxb}{{a}{1}{\betterxb \relax }{figure.caption.2}{}}
\newlabel{fig:exp_iv_save_skltweet}{{2b}{1}{\skltweet \relax }{figure.caption.2}{}}
\newlabel{sub@fig:exp_iv_save_skltweet}{{b}{1}{\skltweet \relax }{figure.caption.2}{}}
\newlabel{fig:exp_iv_ecdf_tpsmay}{{2c}{1}{\tpsmay \relax }{figure.caption.2}{}}
\newlabel{sub@fig:exp_iv_ecdf_tpsmay}{{c}{1}{\tpsmay \relax }{figure.caption.2}{}}
\newlabel{fig:exp_iv_ecdf_twittnet}{{2d}{1}{\twittnet \relax }{figure.caption.2}{}}
\newlabel{sub@fig:exp_iv_ecdf_twittnet}{{d}{1}{\twittnet \relax }{figure.caption.2}{}}
\newlabel{fig:exp_iv_ecdf_aicode}{{2e}{1}{\aicode \relax }{figure.caption.2}{}}
\newlabel{sub@fig:exp_iv_ecdf_aicode}{{e}{1}{\aicode \relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Empirical cumulative distributions (eCDFs) of the saving times (closer to the top-left corner are better).\relax }}{1}{figure.caption.2}\protected@file@percent }
\newlabel{fig:exp_iv_ecdf}{{2}{1}{Empirical cumulative distributions (eCDFs) of the saving times (closer to the top-left corner are better).\relax }{figure.caption.2}{}}
\newlabel{fig:exp_i_partial_load_betterxb}{{3a}{1}{\betterxb \relax }{figure.caption.3}{}}
\newlabel{sub@fig:exp_i_partial_load_betterxb}{{a}{1}{\betterxb \relax }{figure.caption.3}{}}
\newlabel{fig:exp_i_partial_load_skltweet}{{3b}{1}{\skltweet \relax }{figure.caption.3}{}}
\newlabel{sub@fig:exp_i_partial_load_skltweet}{{b}{1}{\skltweet \relax }{figure.caption.3}{}}
\newlabel{fig:exp_i_partial_load_tpsmay}{{3c}{1}{\tpsmay \relax }{figure.caption.3}{}}
\newlabel{sub@fig:exp_i_partial_load_tpsmay}{{c}{1}{\tpsmay \relax }{figure.caption.3}{}}
\newlabel{fig:exp_i_partial_load_twittnet}{{3d}{1}{\twittnet \relax }{figure.caption.3}{}}
\newlabel{sub@fig:exp_i_partial_load_twittnet}{{d}{1}{\twittnet \relax }{figure.caption.3}{}}
\newlabel{fig:exp_i_partial_load_aicode}{{3e}{1}{\aicode \relax }{figure.caption.3}{}}
\newlabel{sub@fig:exp_i_partial_load_aicode}{{e}{1}{\aicode \relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Partial loading time when users are interested in variables accessed at each cell. \textsf  {Chipmink}\xspace  quickly load target variables proportionally to their individual sizes, whereas some baselines' performance depend on the entire namespace size.\relax }}{1}{figure.caption.3}\protected@file@percent }
\newlabel{fig:exp_i_partial_load}{{3}{1}{Partial loading time when users are interested in variables accessed at each cell. \pga quickly load target variables proportionally to their individual sizes, whereas some baselines' performance depend on the entire namespace size.\relax }{figure.caption.3}{}}
\newlabel{fig:exp_ii_avf_storage}{{4a}{1}{Total storage size\relax }{figure.caption.4}{}}
\newlabel{sub@fig:exp_ii_avf_storage}{{a}{1}{Total storage size\relax }{figure.caption.4}{}}
\newlabel{fig:exp_ii_avf_save}{{4b}{1}{Average overhead saving time\relax }{figure.caption.4}{}}
\newlabel{sub@fig:exp_ii_avf_save}{{b}{1}{Average overhead saving time\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Ablation study: change detector (CD) and active variable filter (AVF) contribute to storage savings and speedups.\relax }}{1}{figure.caption.4}\protected@file@percent }
\newlabel{fig:exp_ii_avf}{{4}{1}{Ablation study: change detector (CD) and active variable filter (AVF) contribute to storage savings and speedups.\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Higher thesaurus capacity reduces storage usage by detecting more synonymous pods. In these notebooks, storage usage converges with $k_{\text  {cap}}$ around 100\nonbreakingspace KB.\relax }}{1}{figure.caption.5}\protected@file@percent }
\newlabel{fig:exp_ii_cache_storage}{{5}{1}{Higher thesaurus capacity reduces storage usage by detecting more synonymous pods. In these notebooks, storage usage converges with $k_{\text {cap}}$ around 100~KB.\relax }{figure.caption.5}{}}
\newlabel{fig:exp_iii_storage}{{6a}{2}{Total storage size\relax }{figure.caption.6}{}}
\newlabel{sub@fig:exp_iii_storage}{{a}{2}{Total storage size\relax }{figure.caption.6}{}}
\newlabel{fig:exp_iii_save}{{6b}{2}{Average overhead saving time\relax }{figure.caption.6}{}}
\newlabel{sub@fig:exp_iii_save}{{b}{2}{Average overhead saving time\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces \textsf  {LGA}\xspace  is the most effective podding optimizer in discovering compact podding compared to naive methods (\textsf  {BundleAll}\xspace  , \textsf  {SplitAll}\xspace  , \textsf  {Random}\xspace  ), manually derived heuristic (\textsf  {TbH}\xspace  ), and \textsf  {LGA}\xspace  with inacBurate volatility models (\textsf  {LGA-0}\xspace  , \textsf  {LGA-1}\xspace  ).\relax }}{2}{figure.caption.6}\protected@file@percent }
\newlabel{fig:exp_iii}{{6}{2}{\pglga is the most effective podding optimizer in discovering compact podding compared to naive methods (\bundle , \pnv , \prand ), manually derived heuristic (\pfl ), and \pglga with inacBurate volatility models (\pgz , \pgi ).\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces With parallel saving, active variable locking (AVL) and allowlist-based static code checker (ASCC) unblocks user's cell executions, improving over synchronous saving.\relax }}{2}{figure.caption.7}\protected@file@percent }
\newlabel{fig:exp_iv_ecdf_compare}{{7}{2}{With parallel saving, active variable locking (AVL) and allowlist-based static code checker (ASCC) unblocks user's cell executions, improving over synchronous saving.\relax }{figure.caption.7}{}}
\newlabel{TotPages}{{2}{2}{}{page.2}{}}
\gdef \@abspage@last{2}
