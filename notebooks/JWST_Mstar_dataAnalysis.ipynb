{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# MRS Detector Based Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use case:** This notebook illustrates a spectral extraction technique from detector image plane using a PSF model and the pixel variance. This extraction is considered more advanced than what is currently implemented in the JWST pipeline and is expected to be fully integrated into the pipeline in the future.<br>\n",
    "**Data:** Simulated [MIRI MRS](https://jwst-docs.stsci.edu/mid-infrared-instrument/miri-observing-modes/miri-medium-resolution-spectroscopy) spectrum of AGB star.<br>\n",
    "**Tools:** jwst, astropy, numpy, scipy.<br>\n",
    "**Cross-intrument:** No. <br>\n",
    "**Documentation:** This notebook is part of a STScI's larger [post-pipeline Data Analysis Tools Ecosystem](https://jwst-docs.stsci.edu/jwst-post-pipeline-data-analysis) and can be [downloaded](https://github.com/spacetelescope/dat_pyinthesky/tree/main/jdat_notebooks/MRS_Mstar_analysis) directly from the [JDAT Notebook Github directory](https://github.com/spacetelescope/jdat_notebooks).<br>\n",
    "**Source of Simulations:** [MIRISim](https://www.stsci.edu/jwst/science-planning/proposal-planning-toolbox/mirisim)<br>\n",
    "**Pipeline Version:** [JWST Pipeline](https://jwst-docs.stsci.edu/jwst-data-reduction-pipeline)<br>\n",
    "\n",
    "**Note**: This notebook includes MIRI simulated data cubes obtained using MIRISim (https://wiki.miricle.org//bin/view/Public/MIRISim_Public) and run through the JWST pipeline (https://jwst-pipeline.readthedocs.io/en/latest/) of point sources with spectra representative of late M type stars.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook analyzes one star represented by a dusty SED corresponding to the ISO SWS spectrum of W Per from Kraemer et al. (2002) and Sloan et al. (2003) to cover the MRS spectral range 5-28 microns.  Analysis of JWST spectral cubes requires extracting spatial-spectral features of interest and measuring their attributes.\n",
    "\n",
    "This is the first notebook, which will process the data and automatically detect and extract spectra for the point source.  The workflow automatically detects sources on the detector image plane to extract the spectrum of the point source. Then it will read in the spectra generated at Stage 3 of the JWST pipeline.\n",
    "\n",
    "## Motivation to the Detector Based Extraction Technique\n",
    "\n",
    "At present, one-dimensional spectra produced by the JWST pipeline are\n",
    " constructed exclusively from the combined and rectified 3-dimensional\n",
    "data cubes.  These data cubes are treated as a collection of images at\n",
    "various wavelength planes, and simple aperture-based (or effective\n",
    "PSF-weighted) techniques are used to recover the source intensity as a\n",
    "function of wavelength in a manner akin to standard imaging PSF\n",
    "photometry.  However, this method of extracting point source spectra\n",
    "from data cubes is not ideal; fundamentally, a source with no spatial\n",
    "structure should not undergo spatial reprocessing prior to extraction of\n",
    "spectral information.  Indeed, large-scale IFU surveys targeting point\n",
    "sources rather than extended sources (e.g., SDSS IV/MaStar, R. Yan et\n",
    "al. 2019) have relied on detector-based spectral extraction rather than\n",
    "the construction of 3d data cubes.\n",
    " \n",
    "For the MIRI MRS in particular, such detector-based extraction offers\n",
    "the opportunity to correct for the following effects which would be\n",
    "difficult or impossible to handle once the observational data has been\n",
    "rectified into 3-dimensional cubes:\n",
    "\n",
    "1) Given the significant undersampling of the MRS, offsets in spaxel\n",
    "sampling locations as a function of wavelength can alias spatial\n",
    "structure from the point spread function into spectral artifacts that\n",
    "bias extracted 1D spectra.  3D cube building is designed in a manner to\n",
    "mitigate these artifacts, but the act of resampling ensures that 1D\n",
    "spectra of unresolved sources extracted from 3D cubes can never be as\n",
    "reliable as 1D spectra extracted directly from detector-level data\n",
    "without the intermediate resampling step.\n",
    "\n",
    "2) Resampled pixels in the data cubes have significant covariance with\n",
    "adjacent/nearby pixels.  Treating this covariance properly in the\n",
    "construction of extracted 1D spectra with flux and variance information\n",
    "is challenging, and not handled at present by the cube-based spectral\n",
    "extraction.\n",
    "\n",
    "3) Pipeline calibrations of the instrument throughput and wavelength\n",
    "calibration are based on sources that fill a given IFU slice, whereas\n",
    "point sources produce a non-uniform response depending upon the location\n",
    "of the source centroid within a given IFU slice.  For instance, given\n",
    "the degeneracy on the detector between the spatial across-slice and\n",
    "spectral dispersion directions, the wavelength solution for point\n",
    "sources will differ slightly than for extended sources in a manner that\n",
    "depends on the source location within the slice.  This effect cannot be\n",
    "recovered once a 3D cube has been constructed that combines data from\n",
    "many slices (and indeed, multiple dithered exposures).\n",
    "\n",
    "4) The MRS has a spectral leak in which 2nd order light from 6 microns\n",
    "(Ch1B) is visible at a few percent transmission in the 12 micron\n",
    "observations (Ch3A).  This effect is not possible to correct in general,\n",
    "since the Ch3A field of view is larger than that of Ch1B.  However, for\n",
    "the specific case of a point source within the common field of view of\n",
    "all channels it is possible to use the Ch1B spectrum to predict and\n",
    "subtract the second-order signal from the Ch3A data.\n",
    "\n",
    "## Implementation of the Algorithm\n",
    "\n",
    "In this notebook, we implement a method for achieving MIRI MRS\n",
    "detector-based point source extraction. The formalism behind the method\n",
    "follows the optimal spectral extraction formalism by Keith Horne 1986.\n",
    "Extracting a 1d integrated spectrum directly from the MRS detectors\n",
    "depends on (a) a detailed knowledge of the detector PSF, and (b) the\n",
    "pixel variance. The MRS detector PSF differs considerably from the\n",
    "telescope PSF due to the scattering of the photons inside the detector\n",
    "substrate. How well the detector PSF is understood/modeled/measured is\n",
    "key in this instance and should not be understated. For the pixel\n",
    "variance, the slope-fitting uncertainty from the pixel integration\n",
    "ramp(s) is used. The combination of the detector PSF and pixel variance\n",
    "is used as a weighing function to weigh the signal in each detector pixel.\n",
    "\n",
    "In its most basic form, the notebook code assumes that there is only one\n",
    "point source in the MRS field of view. Using a Gaussian-fitting routine\n",
    "at detector-level, the centroid of the point source is determined with a\n",
    "sub-pixel accuracy. The centroid is used to project the known detector\n",
    "PSF model directly onto the point source signal. The centroid is also\n",
    "used to derive the throughput and wavelength correction due to the\n",
    "location of the point source with respect to the imaging slicer of the\n",
    "MRS. The throughput and wavelength correction are applied before the\n",
    "spectral extraction step.\n",
    "\n",
    "The spectral extraction step integrates the point source flux in a\n",
    "pre-defined list of wavelength bins. All detector pixels contributing to\n",
    "a wavelength bin are weighed by the projected PSF model -and- the pixel\n",
    "variance. In case the extracted spectral band is MRS band 3A (around 12\n",
    "microns) then the following steps are taken:\n",
    "- The band 1B (~6 micron) detector image is multiplied by a spectral\n",
    "leak transmission curve.\n",
    "- A 1d “spectral leak” integrated point source spectrum is extracted\n",
    "from band 1B.\n",
    "- The spectral leak spectrum is subtracted from the band 3A integrated\n",
    "point source spectrum.\n",
    "\n",
    "Future improvements to the code will allow users to input MRS point\n",
    "source centroid locations to address the case of crowded fields, barely\n",
    "resolved blended point sources, and point sources located within a\n",
    "semi-extended environment with spatial structure. In addition, the fine\n",
    "centroiding, currently performed using a Gaussian distribution, can be\n",
    "improved by striving for residual minimisation with a master\n",
    "detector-based PSF model. Such a master PSF model will be derived and\n",
    "refined throughout commissioning and Cycle 1 calibration. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Import useful python packages\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# Import packages to display images in the notebook\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.pyplot as plt    \n",
    "\n",
    "# Set general plotting options\n",
    "params = {'legend.fontsize': '18', 'axes.labelsize': '18', \n",
    "          'axes.titlesize': '18', 'xtick.labelsize': '18', \n",
    "          'ytick.labelsize': '18', 'lines.linewidth': 2, 'axes.linewidth': 2, 'animation.html': 'html5'}\n",
    "plt.rcParams.update(params)\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import astropy packages \n",
    "from astropy import units as u\n",
    "from astropy.io import ascii\n",
    "from astropy.wcs import WCS\n",
    "from astropy.table import Table, vstack\n",
    "from astropy.stats import sigma_clipped_stats\n",
    "from astropy.nddata import StdDevUncertainty\n",
    "from astropy.io import fits # added by BAS on 8 April 2021\n",
    "from astropy.utils.data import get_pkg_data_filename\n",
    "from astropy.utils.data import download_file\n",
    "\n",
    "# To find stars in the MRS spectralcubes and do aperture photometry\n",
    "from photutils import DAOStarFinder, CircularAperture\n",
    "\n",
    "# To deal with 1D spectrum\n",
    "from specutils import Spectrum1D\n",
    "from specutils.fitting import fit_generic_continuum\n",
    "from specutils.manipulation import box_smooth, extract_region, SplineInterpolatedResampler\n",
    "from specutils.analysis import line_flux, centroid, equivalent_width\n",
    "from specutils.spectra import SpectralRegion\n",
    "from specutils import SpectrumList\n",
    "\n",
    "# To make nice plots with WCS axis\n",
    "# import aplpy\n",
    "\n",
    "# To fit a curve to the data\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# To download data\n",
    "import tarfile\n",
    "import urllib.request\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Functions file used in JDAT notebook: JWST_Mstar_dataAnalysis_PointSourceDetectorBasedExtraction.ipynb\n",
    ":History:\n",
    "Created on Mon Jan 10 10:15:00 2022\n",
    "@author: Dr. Ioannis Argyriou (Institute of Astronomy, KU Leuven, Belgium, ioannis.argyriou@kuleuven.be)\n",
    "\"\"\"\n",
    "\n",
    "# import python modules\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "import scipy.interpolate as scp_interpolate\n",
    "# Definition\n",
    "#--auxilliary data\n",
    "def mrs_aux(band):\n",
    "    allbands = ['1A','1B','1C','2A','2B','2C','3A','3B','3C','4A','4B','4C']\n",
    "    allchannels = ['1','2','3','4']\n",
    "    allsubchannels = ['A','B','C']\n",
    "\n",
    "    # slice IDs on detector\n",
    "    sliceid1=[111,121,110,120,109,119,108,118,107,117,106,116,105,115,104,114,103,113,102,112,101]\n",
    "    sliceid2=[201,210,202,211,203,212,204,213,205,214,206,215,207,216,208,217,209]\n",
    "    sliceid3=[316,308,315,307,314,306,313,305,312,304,311,303,310,302,309,301]\n",
    "    sliceid4=[412,406,411,405,410,404,409,403,408,402,407,401]\n",
    "\n",
    "    MRS_bands = {'1A':[4.885,5.751],\n",
    "        '1B':[5.634,6.632],\n",
    "        '1C':[6.408,7.524],\n",
    "        '2A':[7.477,8.765],\n",
    "        '2B':[8.711,10.228],\n",
    "        '2C':[10.017,11.753],\n",
    "        '3A':[11.481,13.441],\n",
    "        '3B':[13.319,15.592],\n",
    "        '3C':[15.4,18.072],\n",
    "        '4A':[17.651,20.938],\n",
    "        '4B':[20.417,24.22],\n",
    "        '4C':[23.884,28.329]} # microns\n",
    "\n",
    "    MRS_R = {'1A':[3320.,3710.],\n",
    "        '1B':[3190.,3750.],\n",
    "        '1C':[3100.,3610.],\n",
    "        '2A':[2990.,3110.],\n",
    "        '2B':[2750.,3170.],\n",
    "        '2C':[2860.,3300.],\n",
    "        '3A':[2530.,2880.],\n",
    "        '3B':[1790.,2640.],\n",
    "        '3C':[1980.,2790.],\n",
    "        '4A':[1460.,1930.],\n",
    "        '4B':[1680.,1770.],\n",
    "        '4C':[1630.,1330.]} # R = lambda / delta_lambda\n",
    "\n",
    "    MRS_lambpix = {'1A':0.0008,\n",
    "        '1B':0.0009,\n",
    "        '1C':0.001,\n",
    "        '2A':0.0014,\n",
    "        '2B':0.0017,\n",
    "        '2C':0.0020,\n",
    "        '3A':0.0023,\n",
    "        '3B':0.0026,\n",
    "        '3C':0.0030,\n",
    "        '4A':0.0036,\n",
    "        '4B':0.0042,\n",
    "        '4C':0.0048} # average pixel spectral size\n",
    "\n",
    "    MRS_nslices = {'1':21,'2':17,'3':16,'4':12} # number of slices\n",
    "\n",
    "    MRS_alphapix = {'1':0.196,'2':0.196,'3':0.245,'4':0.273} # arcseconds\n",
    "\n",
    "    MRS_slice = {'1':0.176,'2':0.277,'3':0.387,'4':0.645} # arcseconds\n",
    "\n",
    "    MRS_FOV = {'1':[3.70,3.70],'2':[4.51,4.71],'3':[6.13,6.19],'4':[7.74,7.74]} # arcseconds along and across slices\n",
    "\n",
    "    MRS_FWHM = {'1':0.423,'2':0.647,'3':0.99,'4':1.518} # MRS PSF\n",
    "\n",
    "    return allbands,allchannels,allsubchannels,MRS_bands[band],MRS_R[band],MRS_alphapix[band[0]],MRS_slice[band[0]],MRS_FOV[band[0]],MRS_FWHM[band[0]],MRS_lambpix[band]\n",
    "\n",
    "def gauss1d_wBaseline(x, A, mu, sigma, baseline):\n",
    "    return  A*np.exp(-(x-mu)**2/(2*sigma)**2) + baseline\n",
    "\n",
    "def gauss2d(xy, amp, x0, y0, sigma_x, sigma_y, base):\n",
    "    # assert that values are floats\n",
    "    amp, x0, y0, sigma_x, sigma_y, base = float(amp),float(x0),float(y0),float(sigma_x),float(sigma_y),float(base)\n",
    "    x, y = xy\n",
    "    a = 1/(2*sigma_x**2)\n",
    "    b = 1/(2*sigma_y**2)\n",
    "    inner = a * (x - x0)**2\n",
    "    inner += b * (y - y0)**2\n",
    "    return amp * np.exp(-inner) + base\n",
    "\n",
    "def point_source_centroiding(band,sci_img,d2cMaps,spec_grid=None,fit='2D',center=None,offset_slice=0,verbose=True):\n",
    "    # distortion maps\n",
    "    sliceMap  = d2cMaps['sliceMap']\n",
    "    lambdaMap = d2cMaps['lambdaMap']\n",
    "    alphaMap  = d2cMaps['alphaMap']\n",
    "    betaMap   = d2cMaps['betaMap']\n",
    "    nslices   = d2cMaps['nslices']\n",
    "    MRS_alphapix = {'1':0.196,'2':0.196,'3':0.245,'4':0.273} # arcseconds\n",
    "    MRS_FWHM = {'1':2.16*MRS_alphapix['1'],'2':3.30*MRS_alphapix['2'],\n",
    "                '3':4.04*MRS_alphapix['3'],'4':5.56*MRS_alphapix['4']} # MRS PSF\n",
    "    mrs_fwhm  = MRS_FWHM[band[0]]\n",
    "    lambcens,lambfwhms = spec_grid[0],spec_grid[1]\n",
    "    unique_betas = np.sort(np.unique(betaMap[(sliceMap>100*int(band[0])) & (sliceMap<100*(int(band[0])+1))]))\n",
    "    fov_lims  = [alphaMap[np.nonzero(lambdaMap)].min(),alphaMap[np.nonzero(lambdaMap)].max()]\n",
    "\n",
    "    if verbose:\n",
    "        print('STEP 1: Rough centroiding')\n",
    "    if center is None:\n",
    "        # premise> center of point source is located in slice with largest signal\n",
    "        # across-slice center:\n",
    "        sum_signals = np.zeros(nslices)\n",
    "        for islice in range(1,1+nslices):\n",
    "            sum_signals[islice-1] = sci_img[(sliceMap == 100*int(band[0])+islice) & (~np.isnan(sci_img))].sum()\n",
    "        source_center_slice = np.argmax(sum_signals)+1\n",
    "        source_center_slice+=offset_slice\n",
    "\n",
    "        # along-slice center:\n",
    "        det_dims = (1024,1032)\n",
    "        img = np.full(det_dims,0.)\n",
    "        sel = (sliceMap == 100*int(band[0])+source_center_slice)\n",
    "        img[sel]  = sci_img[sel]\n",
    "\n",
    "        source_center_alphas = []\n",
    "        for row in range(det_dims[0]):\n",
    "            source_center_alphas.append(alphaMap[row,img[row,:].argmax()])\n",
    "        source_center_alphas = np.array(source_center_alphas)\n",
    "        source_center_alpha  = np.average(source_center_alphas[~np.isnan(source_center_alphas)])\n",
    "    else:\n",
    "        source_center_slice,source_center_alpha = center[0],center[1]\n",
    "    if verbose:\n",
    "        # summary:\n",
    "        print( 'Slice {} has the largest summed flux'.format(source_center_slice))\n",
    "        print( 'Source position: beta = {}arcsec, alpha = {}arcsec \\n'.format(round(unique_betas[source_center_slice-1],2),round(source_center_alpha,2)))\n",
    "\n",
    "    if fit == '0D':\n",
    "        return source_center_slice,unique_betas[source_center_slice-1],source_center_alpha\n",
    "\n",
    "    if verbose:\n",
    "        print( 'STEP 2: 1D Gaussian fit')\n",
    "\n",
    "    # Fit Gaussian distribution to along-slice signal profile\n",
    "    sign_amp,alpha_centers,alpha_fwhms,bkg_signal = [np.full((len(lambcens)),np.nan) for j in range(4)]\n",
    "    sign_amp_sliceoffsetminus1,alpha_centers_sliceoffsetminus1,alpha_fwhms_sliceoffsetminus1,bkg_signal_sliceoffsetminus1 = [np.full((len(lambcens)),np.nan) for j in range(4)]\n",
    "    sign_amp_sliceoffsetplus1,alpha_centers_sliceoffsetplus1,alpha_fwhms_sliceoffsetplus1,bkg_signal_sliceoffsetplus1 = [np.full((len(lambcens)),np.nan) for j in range(4)]\n",
    "    failed_fits = []\n",
    "    for ibin in range(len(lambcens)):\n",
    "        coords = np.where((sliceMap == 100*int(band[0])+source_center_slice) & (np.abs(lambdaMap-lambcens[ibin])<=lambfwhms[ibin]/2.) & (~np.isnan(sci_img)))\n",
    "        coords_sliceoffsetminus1 = np.where((sliceMap == 100*int(band[0])+source_center_slice-1) & (np.abs(lambdaMap-lambcens[ibin])<=lambfwhms[ibin]/2.) & (~np.isnan(sci_img)))\n",
    "        coords_sliceoffsetplus1 = np.where((sliceMap == 100*int(band[0])+source_center_slice+1) & (np.abs(lambdaMap-lambcens[ibin])<=lambfwhms[ibin]/2.) & (~np.isnan(sci_img)))\n",
    "        if len(coords[0]) == 0:\n",
    "            failed_fits.append(ibin); continue\n",
    "        try:\n",
    "            popt,pcov = curve_fit(gauss1d_wBaseline, alphaMap[coords], sci_img[coords], p0=[sci_img[coords].max(),source_center_alpha,mrs_fwhm/2.355,0],method='lm')\n",
    "            popt_sliceoffsetminus1,pcov = curve_fit(gauss1d_wBaseline, alphaMap[coords_sliceoffsetminus1], sci_img[coords_sliceoffsetminus1], p0=[sci_img[coords_sliceoffsetminus1].max(),source_center_alpha,mrs_fwhm/2.355,0],method='lm')\n",
    "            popt_sliceoffsetplus1,pcov = curve_fit(gauss1d_wBaseline, alphaMap[coords_sliceoffsetplus1], sci_img[coords_sliceoffsetplus1], p0=[sci_img[coords_sliceoffsetplus1].max(),source_center_alpha,mrs_fwhm/2.355,0],method='lm')\n",
    "        except:\n",
    "            failed_fits.append(ibin); continue\n",
    "        sign_amp[ibin]      = popt[0]+popt[3]\n",
    "        alpha_centers[ibin] = popt[1]\n",
    "        alpha_fwhms[ibin]   = 2.355*np.abs(popt[2])\n",
    "        bkg_signal[ibin]    = popt[3]\n",
    "\n",
    "        sign_amp_sliceoffsetminus1[ibin]      = popt_sliceoffsetminus1[0]+popt_sliceoffsetminus1[3]\n",
    "        alpha_centers_sliceoffsetminus1[ibin] = popt_sliceoffsetminus1[1]\n",
    "        alpha_fwhms_sliceoffsetminus1[ibin]   = 2.355*np.abs(popt_sliceoffsetminus1[2])\n",
    "        bkg_signal_sliceoffsetminus1[ibin]    = popt_sliceoffsetminus1[3]\n",
    "\n",
    "        sign_amp_sliceoffsetplus1[ibin]      = popt_sliceoffsetplus1[0]+popt_sliceoffsetplus1[3]\n",
    "        alpha_centers_sliceoffsetplus1[ibin] = popt_sliceoffsetplus1[1]\n",
    "        alpha_fwhms_sliceoffsetplus1[ibin]   = 2.355*np.abs(popt_sliceoffsetplus1[2])\n",
    "        bkg_signal_sliceoffsetplus1[ibin]    = popt_sliceoffsetplus1[3]\n",
    "\n",
    "    # omit outliers\n",
    "    for i in range(len(np.diff(sign_amp))):\n",
    "        if np.abs(np.diff(alpha_centers)[i]) > 0.05:\n",
    "            sign_amp[i],sign_amp[i+1],alpha_centers[i],alpha_centers[i+1],alpha_fwhms[i],alpha_fwhms[i+1] = [np.nan for j in range(6)]\n",
    "\n",
    "    if verbose:\n",
    "        print( '[Along-slice fit] The following bins failed to converge:')\n",
    "        print( failed_fits)\n",
    "\n",
    "    # Fit Gaussian distribution to across-slice signal profile (signal brute-summed in each slice)\n",
    "    summed_signal,beta_centers,beta_fwhms = [np.full((len(lambcens)),np.nan) for j in range(3)]\n",
    "    failed_fits = []\n",
    "    for ibin in range(len(lambcens)):\n",
    "        if np.isnan(alpha_centers[ibin]):\n",
    "            failed_fits.append(ibin)\n",
    "            continue\n",
    "        sel = (np.abs(lambdaMap-lambcens[ibin])<=lambfwhms[ibin]/2.) & (~np.isnan(sci_img))\n",
    "        try:\n",
    "            signals = np.array([sci_img[(sliceMap == 100*int(band[0])+islice) & sel][np.abs(alphaMap[(sliceMap == 100*int(band[0])+islice) & sel]-alpha_centers[ibin]).argmin()] for islice in range(1,1+nslices)])\n",
    "            signals[source_center_slice-2:source_center_slice+1] = np.array([sign_amp_sliceoffsetminus1[ibin],sign_amp[ibin],sign_amp_sliceoffsetplus1[ibin]])\n",
    "        except ValueError:\n",
    "            failed_fits.append(ibin)\n",
    "            continue\n",
    "        try:\n",
    "            popt,pcov = curve_fit(gauss1d_wBaseline, unique_betas, signals, p0=[signals.max(),unique_betas[source_center_slice-1],mrs_fwhm/2.355,0],method='lm')\n",
    "        except:\n",
    "            failed_fits.append(ibin)\n",
    "            continue\n",
    "        summed_signal[ibin] = popt[0]+popt[3]\n",
    "        beta_centers[ibin]  = popt[1]\n",
    "        beta_fwhms[ibin]    = 2.355*np.abs(popt[2])\n",
    "\n",
    "    # # omit outliers\n",
    "    # for i in range(len(np.diff(summed_signal))):\n",
    "    #     if np.abs(np.diff(beta_centers)[i]) > 0.05:\n",
    "    #         summed_signal[i],summed_signal[i+1],beta_centers[i],beta_centers[i+1],beta_fwhms[i],beta_fwhms[i+1] = [np.nan for j in range(6)]\n",
    "    if verbose:\n",
    "        print( '[Across-slice fit] The following bins failed to converge:')\n",
    "        print( failed_fits)\n",
    "        print( '')\n",
    "\n",
    "    if fit == '1D':\n",
    "        sigma_alpha, sigma_beta = alpha_fwhms/2.355, beta_fwhms/2.355\n",
    "        return sign_amp,alpha_centers,beta_centers,sigma_alpha,sigma_beta,bkg_signal\n",
    "\n",
    "    elif fit == '2D':\n",
    "        if verbose:\n",
    "            print( 'STEP 3: 2D Gaussian fit')\n",
    "        sign_amp2D,alpha_centers2D,beta_centers2D,sigma_alpha2D,sigma_beta2D,bkg_amp2D = [np.full((len(lambcens)),np.nan) for j in range(6)]\n",
    "        failed_fits = []\n",
    "\n",
    "        for ibin in range(len(lambcens)):\n",
    "            # initial guess for fitting, informed by previous centroiding steps\n",
    "            amp,alpha0,beta0  = sign_amp[ibin],alpha_centers[ibin],beta_centers[ibin]\n",
    "            sigma_alpha, sigma_beta = alpha_fwhms[ibin]/2.355, beta_fwhms[ibin]/2.355\n",
    "            base = 0\n",
    "            guess = [amp, alpha0, beta0, sigma_alpha, sigma_beta, base]\n",
    "            bounds = ([0,-np.inf,-np.inf,0,0,-np.inf],[np.inf,np.inf,np.inf,np.inf,np.inf,np.inf])\n",
    "\n",
    "            # data to fit\n",
    "            coords = (np.abs(lambdaMap-lambcens[ibin])<lambfwhms[ibin]/2.)\n",
    "            alphas, betas, zobs   = alphaMap[coords],betaMap[coords],sci_img[coords]\n",
    "            alphabetas = np.array([alphas,betas])\n",
    "\n",
    "            # perform fitting\n",
    "            try:\n",
    "                popt,pcov = curve_fit(gauss2d, alphabetas, zobs, p0=guess,bounds=bounds)\n",
    "            except:\n",
    "                failed_fits.append(ibin); continue\n",
    "\n",
    "            sign_amp2D[ibin]      = popt[0]\n",
    "            alpha_centers2D[ibin] = popt[1]\n",
    "            beta_centers2D[ibin]  = popt[2]\n",
    "            sigma_alpha2D[ibin]   = popt[3]\n",
    "            sigma_beta2D[ibin]    = popt[4]\n",
    "            bkg_amp2D[ibin]       = popt[5]\n",
    "        if verbose:\n",
    "            print( 'The following bins failed to converge:')\n",
    "            print( failed_fits)\n",
    "\n",
    "        return sign_amp2D,alpha_centers2D,beta_centers2D,sigma_alpha2D,sigma_beta2D,bkg_amp2D\n",
    "\n",
    "def evaluate_psf_cdp(psffits,d2cMaps,source_center=[0,0],norm=True,cdp_slice=None):\n",
    "    # PSF CDP is provided as a spectral cube\n",
    "    #>get values\n",
    "    psf_values = psffits[1].data.transpose(2,1,0).copy() # flip data from Z,Y,X to X,Y,Z\n",
    "    if norm:\n",
    "        #>normalize values\n",
    "        print('Normalizing PSF (divide by sum of all spaxel values)')\n",
    "        for layer in range(psf_values.shape[2]):\n",
    "            psf_values[:,:,layer] /= psf_values[:,:,layer].sum()\n",
    "    if cdp_slice is not None:\n",
    "        # use only a single layer of the PSF CDP cube\n",
    "        print('Using single slice of PSF cube')\n",
    "        for layer in range(psf_values.shape[2]):\n",
    "            psf_values[:,:,layer] = psf_values[:,:,cdp_slice]\n",
    "\n",
    "    #>get grid\n",
    "    NAXIS1,NAXIS2,NAXIS3 = psf_values.shape\n",
    "\n",
    "    alphastpix = psffits[1].header['CRPIX1'] # pixel nr\n",
    "    alpha_step = psffits[1].header['CDELT1'] # arcsec/pix\n",
    "    stalpha    = psffits[1].header['CRVAL1']-(alphastpix-1)*alpha_step # arcsec\n",
    "\n",
    "    betastpix = psffits[1].header['CRPIX2'] # pixel nr\n",
    "    beta_step = psffits[1].header['CDELT2'] # arcsec/pix\n",
    "    stbeta    = psffits[1].header['CRVAL2']-(betastpix-1)*beta_step # arcsec\n",
    "\n",
    "    stwavl = psffits[1].header['CRVAL3'] # microns\n",
    "    wavl_step   = psffits[1].header['CDELT3'] # microns/pix\n",
    "\n",
    "    alpha_slices = np.linspace(stalpha,stalpha+ (NAXIS1-1.5)*alpha_step,NAXIS1)\n",
    "    beta_slices  = np.linspace(stbeta,stbeta+ (NAXIS2-1.5)*beta_step,NAXIS2)\n",
    "    wvl_slices   = np.linspace(stwavl ,stwavl+NAXIS3*wavl_step,NAXIS3)\n",
    "\n",
    "    #> center psf to source\n",
    "    alpha_slices += source_center[0]\n",
    "    beta_slices  += source_center[1]\n",
    "\n",
    "    #> create interpolant based on regular grid\n",
    "    interpolpsf = scp_interpolate.RegularGridInterpolator((alpha_slices,beta_slices,wvl_slices),psf_values)\n",
    "    interpolpsf.fill_value=0.\n",
    "    interpolpsf.bounds_error=False\n",
    "\n",
    "    # evaluate psf at each pixel center and pixel corner\n",
    "    alphaULMap = d2cMaps['alphaULMap']\n",
    "    alphaURMap = d2cMaps['alphaURMap']\n",
    "    alphaLLMap = d2cMaps['alphaLLMap']\n",
    "    alphaLRMap = d2cMaps['alphaLRMap']\n",
    "    alphaMap   = d2cMaps['alphaMap']\n",
    "\n",
    "    betaULMap = d2cMaps['betaULMap']\n",
    "    betaURMap = d2cMaps['betaURMap']\n",
    "    betaLLMap = d2cMaps['betaLLMap']\n",
    "    betaLRMap = d2cMaps['betaLRMap']\n",
    "    betaMap   = d2cMaps['betaMap']\n",
    "\n",
    "    lambdaULMap = d2cMaps['lambdaULMap']\n",
    "    lambdaURMap = d2cMaps['lambdaURMap']\n",
    "    lambdaLLMap = d2cMaps['lambdaLLMap']\n",
    "    lambdaLRMap = d2cMaps['lambdaLRMap']\n",
    "    lambdaMap = d2cMaps['lambdaMap']\n",
    "\n",
    "    #> interpolate psf to science image pixel centers and corners\n",
    "    #-- assume no significant change in wavelength over one pixel size\n",
    "    psfUL  = interpolpsf((alphaULMap,betaULMap,lambdaULMap))\n",
    "    psfUR  = interpolpsf((alphaURMap,betaURMap,lambdaURMap))\n",
    "    psfLL  = interpolpsf((alphaLLMap,betaLLMap,lambdaLLMap))\n",
    "    psfLR  = interpolpsf((alphaLRMap,betaLRMap,lambdaLRMap))\n",
    "    psfCEN = interpolpsf((alphaMap,betaMap,lambdaMap))\n",
    "\n",
    "    #> evaluate psf as a weighted average\n",
    "    w = np.array([0.125,0.125,0.125,0.125,0.5]) # WARNING: ARBITRARY!\n",
    "    sumweights = w.sum()\n",
    "\n",
    "    psf = (w[0]*psfUL+w[1]*psfUR+w[2]*psfLL+w[3]*psfLR+w[4]*psfCEN)/sumweights\n",
    "\n",
    "    print('DONE')\n",
    "    return psf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "Function to create cube coordinate maps on detector, based on detector pixel coordinates (\"d2c maps\")\n",
    "The function uses the distortion maps described in MIRI-TN-00001-ETH\n",
    "The output is a single dictionary with:\n",
    "          * one map of slice identifiers for each detector pixel\n",
    "          * one map of spectral (wavelength) coordinates at detector pixel centers\n",
    "          * five maps of along-slice (\"alpha\") spatial coordinates (at center and four corners of each detector pixel)\n",
    "          * five maps of across-slice (\"beta\") spatial coordinates (at center and four corners of each detector pixel)\n",
    "          * the start value of the across-slice spatial coordinate (\"bzero\") and the width of a slice (\"bdel\")\n",
    "Creation date: February 2017\n",
    "Original code author: Dr. Bart Vandenbussche (Institute of Astronomy, KU Leuven)\n",
    "Code edited by Ioannis Argyriou (Institute of Astronomy, KU Leuven)\n",
    "=============EXAMPLE OF USE:===============\n",
    "# import function to desired script\n",
    "from distortionMaps import d2cMapping\n",
    "# Give directory where distortion cdps are located\n",
    "cdpDir   = '/PATH/TO/CDP_DATA/'\n",
    "# choose spectral band\n",
    "band = '2A'\n",
    "# make dictionary containing all cube coordinate maps\n",
    "d2cMaps = d2cMapping(band,cdpDir)\n",
    "# plot wavelength map\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(d2cMaps['lambdaMap'])\n",
    "plt.show()\n",
    "==========================================\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def d2cMapping(band,cdpDir,slice_transmission='80pc',fileversion = \"8B.05.02\"):\n",
    "\n",
    "    # all MRS distortion files\n",
    "    distcdp = {}\n",
    "    distcdp[\"3C\"] = \"MIRI_FM_MIRIFULONG_34LONG_DISTORTION_%s.fits\" %fileversion\n",
    "    distcdp[\"3B\"] = \"MIRI_FM_MIRIFULONG_34MEDIUM_DISTORTION_%s.fits\" %fileversion\n",
    "    distcdp[\"3A\"] = \"MIRI_FM_MIRIFULONG_34SHORT_DISTORTION_%s.fits\" %fileversion\n",
    "\n",
    "    distcdp[\"1C\"] = \"MIRI_FM_MIRIFUSHORT_12LONG_DISTORTION_%s.fits\" %fileversion\n",
    "    distcdp[\"1B\"] = \"MIRI_FM_MIRIFUSHORT_12MEDIUM_DISTORTION_%s.fits\" %fileversion\n",
    "    distcdp[\"1A\"] = \"MIRI_FM_MIRIFUSHORT_12SHORT_DISTORTION_%s.fits\" %fileversion\n",
    "\n",
    "    distcdp[\"4C\"] = distcdp[\"3C\"]\n",
    "    distcdp[\"4B\"] = distcdp[\"3B\"]\n",
    "    distcdp[\"4A\"] = distcdp[\"3A\"]\n",
    "\n",
    "    distcdp[\"2C\"] = distcdp[\"1C\"]\n",
    "    distcdp[\"2B\"] = distcdp[\"1B\"]\n",
    "    distcdp[\"2A\"] = distcdp[\"1A\"]\n",
    "\n",
    "\n",
    "    # import parameters needed for d2c mapping\n",
    "    if fileversion[:5] in ['7B.05','07.05','8B.05','08.05']:\n",
    "        from astropy.io import fits\n",
    "        dist = fits.open(cdpDir+distcdp[band])\n",
    "        alphaPoly = dist['Alpha_CH{}'.format(band[0])].data\n",
    "        lambdaPoly = dist['Lambda_CH{}'.format(band[0])].data\n",
    "        bdel = dist[0].header['B_DEL{}'.format(band[0])]\n",
    "        bzero = dist[0].header['B_ZERO{}'.format(band[0])]\n",
    "\n",
    "        slice_idx = int(slice_transmission[0])-1\n",
    "        sliceMap = dist['Slice_Number'].data[slice_idx,:,:]\n",
    "        dist.close()\n",
    "\n",
    "    else:\n",
    "        from astropy.io import fits\n",
    "        dist = fits.open(cdpDir+distcdp[band])\n",
    "        alphaPoly = dist['Alpha_CH{}'.format(band[0])].data\n",
    "        lambdaPoly = dist['Lambda_CH{}'.format(band[0])].data\n",
    "        bdel = dist[0].header['B_DEL{}'.format(band[0])]\n",
    "        bzero = dist[0].header['B_ZERO{}'.format(band[0])]\n",
    "\n",
    "        slice_idx = int(slice_transmission[0])-1\n",
    "        sliceMap = dist['Slice_Number'].data\n",
    "        dist.close()\n",
    "\n",
    "    # create maps with wavelengths, alpha and beta coordinates and pixel size\n",
    "\n",
    "    channel = int(band[0])\n",
    "    #> slice numbers in the slice map of the distortion CDP for this band\n",
    "    sliceInventory = np.unique(sliceMap)\n",
    "    slicesInBand = sliceInventory[np.where( (sliceInventory >= 100*channel ) & (sliceInventory <100*(channel+1)))]\n",
    "\n",
    "    #> initialise the maps with wavelengths, alpha and beta coordinates of corners for every pixel\n",
    "    lambdaMap  = np.zeros(sliceMap.shape)\n",
    "    lambdaLLMap = np.zeros(sliceMap.shape)\n",
    "    lambdaULMap = np.zeros(sliceMap.shape)\n",
    "    lambdaURMap = np.zeros(sliceMap.shape)\n",
    "    lambdaLRMap = np.zeros(sliceMap.shape)\n",
    "    alphaLLMap = np.zeros(sliceMap.shape)\n",
    "    alphaULMap = np.zeros(sliceMap.shape)\n",
    "    alphaURMap = np.zeros(sliceMap.shape)\n",
    "    alphaLRMap = np.zeros(sliceMap.shape)\n",
    "    betaLLMap  = np.zeros(sliceMap.shape)\n",
    "    betaULMap  = np.zeros(sliceMap.shape)\n",
    "    betaURMap  = np.zeros(sliceMap.shape)\n",
    "    betaLRMap  = np.zeros(sliceMap.shape)\n",
    "    alphaMap   = np.zeros(sliceMap.shape)\n",
    "    betaMap    = np.zeros(sliceMap.shape)\n",
    "\n",
    "    for ss in slicesInBand:\n",
    "        s = int(ss - 100*channel)\n",
    "        #> construct a list of y,x coordinates of detector pixels belonging to slices of this band\n",
    "        pixels = np.where(sliceMap == ss)\n",
    "        #> for all pixels within the band, construct arrays with center y,x coordinates, and y,z\n",
    "        # coordinates of the corners of the pixel\n",
    "        pixelCtry = pixels[0]\n",
    "        pixelCtrx = pixels[1]\n",
    "        # old values!\n",
    "        # pixelLLy = pixelCtry - 0.5\n",
    "        # pixelLLx = pixelCtrx - 0.5\n",
    "        # pixelULy = pixelCtry + 0.5\n",
    "        # pixelULx = pixelCtrx - 0.5\n",
    "        # pixelURy = pixelCtry + 0.5\n",
    "        # pixelURx = pixelCtrx + 0.5\n",
    "        # pixelLRy = pixelCtry - 0.5\n",
    "        # pixelLRx = pixelCtrx + 0.5\n",
    "        # new values (flipped old values)!\n",
    "        pixelLLy = pixelCtry + 0.5\n",
    "        pixelLLx = pixelCtrx - 0.5\n",
    "        pixelULy = pixelCtry - 0.5\n",
    "        pixelULx = pixelCtrx - 0.5\n",
    "        pixelURy = pixelCtry - 0.5\n",
    "        pixelURx = pixelCtrx + 0.5\n",
    "        pixelLRy = pixelCtry + 0.5\n",
    "        pixelLRx = pixelCtrx + 0.5\n",
    "\n",
    "        # Calculate wavelengths for center of the pixels, following (Eq 3) in MIRI-TN-00001-ETH\n",
    "        # lambda(x,y) = SUM_i(SUM_j ( (K_lam(i,j)*(x-xs)**j * y**i)))\n",
    "        lambdasLL = np.zeros(len(pixelCtry))\n",
    "        lambdasLR = np.zeros(len(pixelCtry))\n",
    "        lambdasUL = np.zeros(len(pixelCtry))\n",
    "        lambdasUR = np.zeros(len(pixelCtry))\n",
    "        lambdas   = np.zeros(len(pixelCtry))\n",
    "        lp = lambdaPoly[s-1]\n",
    "        xs = lp[0]\n",
    "        for i in range(5):\n",
    "            for j in range(5):\n",
    "                cIndex = 1 + i*5 + j\n",
    "                lambdasLL = lambdasLL + lp[cIndex]*(pixelLLx-xs)**j * pixelLLy**i\n",
    "                lambdasLR = lambdasLR + lp[cIndex]*(pixelLRx-xs)**j * pixelLRy**i\n",
    "                lambdasUL = lambdasUL + lp[cIndex]*(pixelULx-xs)**j * pixelULy**i\n",
    "                lambdasUR = lambdasUR + lp[cIndex]*(pixelURx-xs)**j * pixelURy**i\n",
    "                lambdas   = lambdas   + lp[cIndex]*(pixelCtrx-xs)**j * pixelCtry**i\n",
    "        lambdaLLMap[pixels] = lambdasLL\n",
    "        lambdaLRMap[pixels] = lambdasLR\n",
    "        lambdaULMap[pixels] = lambdasUL\n",
    "        lambdaURMap[pixels] = lambdasUR\n",
    "        lambdaMap[pixels]   = lambdas\n",
    "\n",
    "        #> Calculate alpha coordinate for the corners of the pixels, following (Eq 2) in\n",
    "        # MIRI-TN-00001-ETH\n",
    "        # alpha(x,y) = SUM_i(SUM_j ( (K_alpha(i,j)*(x-xs)**j * y**i)))\n",
    "        alphasLL = np.zeros(len(pixelCtry))\n",
    "        alphasLR = np.zeros(len(pixelCtry))\n",
    "        alphasUL = np.zeros(len(pixelCtry))\n",
    "        alphasUR = np.zeros(len(pixelCtry))\n",
    "        alphas   = np.zeros(len(pixelCtry))\n",
    "\n",
    "        ap = alphaPoly[s-1]\n",
    "        xs = ap[0]\n",
    "        for i in range(5):\n",
    "            for j in range(5):\n",
    "                cIndex = 1 + i*5 + j\n",
    "                alphasLL = alphasLL + ap[cIndex]*(pixelLLx-xs)**j * pixelLLy**i\n",
    "                alphasLR = alphasLR + ap[cIndex]*(pixelLRx-xs)**j * pixelLRy**i\n",
    "                alphasUL = alphasUL + ap[cIndex]*(pixelULx-xs)**j * pixelULy**i\n",
    "                alphasUR = alphasUR + ap[cIndex]*(pixelURx-xs)**j * pixelURy**i\n",
    "                alphas   = alphas   + ap[cIndex]*(pixelCtrx-xs)**j * pixelCtry**i\n",
    "        alphaLLMap[pixels] = alphasLL\n",
    "        alphaLRMap[pixels] = alphasLR\n",
    "        alphaULMap[pixels] = alphasUL\n",
    "        alphaURMap[pixels] = alphasUR\n",
    "        alphaMap[pixels]   = alphas\n",
    "\n",
    "        #> Calculate beta coordinate for the corners of the pixels, following (Eq 4) in\n",
    "        # MIRI-TN-00001-ETH\n",
    "        # Beta(s) = Beta_zero + (s-1) * Delta_Beta\n",
    "        betasLL = bzero + (s-0.5-1)*bdel\n",
    "        betasLR = bzero + (s-0.5-1)*bdel\n",
    "        betasUL = bzero + (s+0.5-1)*bdel\n",
    "        betasUR = bzero + (s+0.5-1)*bdel\n",
    "        betas   = bzero + (s-1)*bdel\n",
    "\n",
    "        betaLLMap[pixels] = betasLL\n",
    "        betaLRMap[pixels] = betasLR\n",
    "        betaULMap[pixels] = betasUL\n",
    "        betaURMap[pixels] = betasUR\n",
    "        betaMap[pixels]   = betas\n",
    "\n",
    "    d2cMaps = {'sliceMap':sliceMap,'alphaMap':alphaMap,'betaMap':betaMap,'lambdaMap':lambdaMap,\n",
    "               'alphaLLMap':alphaLLMap,'alphaLRMap':alphaLRMap,'alphaULMap':alphaULMap,'alphaURMap':alphaURMap,\n",
    "               'betaLLMap':betaLLMap,'betaLRMap':betaLRMap,'betaULMap':betaULMap,'betaURMap':betaURMap,\n",
    "               'lambdaLLMap':lambdaLLMap,'lambdaLRMap':lambdaLRMap,'lambdaULMap':lambdaULMap,'lambdaURMap':lambdaURMap,\n",
    "               'bdel':bdel,'bzero':bzero,'nslices':len(slicesInBand),'cdp_filename':distcdp[band]}\n",
    "    return d2cMaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set paths to the Data and Outputs\n",
    "\n",
    "Use MIRISim JWST pipeline processed data in future iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CRDS_PATH'] = os.environ['HOME']+'/crds_cache'\n",
    "os.environ['CRDS_SERVER_URL'] = 'https://jwst-crds-pub.stsci.edu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set JWST pipeline paths\n",
    "import os\n",
    "os.environ['CRDS_PATH'] = str(Path(os.environ['HOME']) / 'crds_cache')\n",
    "os.environ['CRDS_SERVER_URL'] = 'https://jwst-crds-pub.stsci.edu'\n",
    "\n",
    "# import JWST pipeline\n",
    "from jdaviz.app import Application\n",
    "from jwst.pipeline import Detector1Pipeline\n",
    "from jwst.pipeline import Spec2Pipeline\n",
    "from jwst.pipeline import Spec3Pipeline\n",
    "from jwst.extract_1d import Extract1dStep\n",
    "from jwst.associations.lib.rules_level3_base import DMS_Level3_Base\n",
    "from jwst.associations import asn_from_list\n",
    "from photutils import aperture_photometry\n",
    "\n",
    "import asdf\n",
    "import crds\n",
    "import json\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_location = Path('/data/elastic-notebook/data/spectroscopy')\n",
    "tar_files = [\n",
    "    '20210413_120546_mirisim.tar.gz', \n",
    "    '20210413_123047_mirisim.tar.gz',\n",
    "    '20210413_125354_mirisim.tar.gz'\n",
    "]\n",
    "tar_paths_full = [tar_location / f for f in tar_files]\n",
    "\n",
    "tar_urls = [\n",
    "    'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/MRS_Mstar_analysis/20210413_120546_mirisim.tar.gz',\n",
    "    'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/MRS_Mstar_analysis/20210413_123047_mirisim.tar.gz',\n",
    "    'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/MRS_Mstar_analysis/20210413_125354_mirisim.tar.gz'\n",
    "]\n",
    "\n",
    "\n",
    "for p, url in zip(tar_paths_full, tar_urls):\n",
    "    # check for un-tarred version of file\n",
    "    tmp = p.parent / p.stem\n",
    "    if os.path.exists(tmp.stem):\n",
    "        print(f\"{p.name} Directory Exists.\")\n",
    "#     else:\n",
    "#         # check for tarred version of file and un-tar\n",
    "#         if not os.path.exists(p):\n",
    "#             # download file if absent\n",
    "#             print(f\"Downloading {p.name}...\")           \n",
    "#             urllib.request.urlretrieve(url, p)\n",
    "        \n",
    "#         tar = tarfile.open(p, \"r:gz\")\n",
    "#         tar.extractall()\n",
    "#         tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Directories If They Don't Exist\n",
    "if os.path.isdir(\"/data/elastic-notebook/data/spectroscopy/miri_devel/cdp_data/DISTORTION\"):\n",
    "    print(\"MIRI Reference File Directory Exists.\")\n",
    "else:\n",
    "    os.makedirs(\"/data/elastic-notebook/data/spectroscopy/miri_devel/cdp_data/DISTORTION\")\n",
    "    print(\"Made Directory ./miri_devel/cdp_data/DISTORTION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('/data/elastic-notebook/data/spectroscopy/')\n",
    "data_paths = [\n",
    "    'spectral_leak_transmission.npy',\n",
    "    'W_Per_spectrum_sws.fit',\n",
    "    'jwst_miri_photom_0064.fits',\n",
    "    'jwst_miri_photom_0060.fits',\n",
    "    'jwst_miri_photom_0052.fits',\n",
    "    'miri_devel/cdp_data/MIRI_FM_MIRIFUSHORT_2SHORT_PSF_07.02.00.fits',\n",
    "    'miri_devel/cdp_data/MIRI_FM_MIRIFUSHORT_2MEDIUM_PSF_07.02.00.fits',\n",
    "    'miri_devel/cdp_data/MIRI_FM_MIRIFUSHORT_2LONG_PSF_07.02.00.fits',\n",
    "    'miri_devel/cdp_data/MIRI_FM_MIRIFUSHORT_1SHORT_PSF_07.02.00.fits',\n",
    "    'miri_devel/cdp_data/MIRI_FM_MIRIFUSHORT_1MEDIUM_PSF_07.02.00.fits',\n",
    "    'miri_devel/cdp_data/MIRI_FM_MIRIFUSHORT_1LONG_PSF_07.02.00.fits',\n",
    "    'miri_devel/cdp_data/MIRI_FM_MIRIFULONG_3SHORT_PSF_07.02.00.fits',\n",
    "    'miri_devel/cdp_data/MIRI_FM_MIRIFULONG_3MEDIUM_PSF_07.02.00.fits',\n",
    "    'miri_devel/cdp_data/MIRI_FM_MIRIFULONG_3LONG_PSF_07.02.00.fits',\n",
    "    'miri_devel/cdp_data/MIRI_FM_MIRIFULONG_4SHORT_PSF_07.02.00.fits',\n",
    "    'miri_devel/cdp_data/MIRI_FM_MIRIFULONG_4MEDIUM_PSF_07.02.00.fits',\n",
    "    'miri_devel/cdp_data/MIRI_FM_MIRIFULONG_4LONG_PSF_07.02.00.fits',\n",
    "    'miri_devel/cdp_data/DISTORTION/MIRI_FM_MIRIFULONG_34LONG_DISTORTION_8B.05.03.fits',\n",
    "    'miri_devel/cdp_data/DISTORTION/MIRI_FM_MIRIFULONG_34LONG_DISTORTION_8B.05.02.fits',\n",
    "    'miri_devel/cdp_data/DISTORTION/MIRI_FM_MIRIFULONG_34MEDIUM_DISTORTION_8B.05.02.fits',\n",
    "    'miri_devel/cdp_data/DISTORTION/MIRI_FM_MIRIFULONG_34MEDIUM_DISTORTION_8B.05.03.fits',\n",
    "    'miri_devel/cdp_data/DISTORTION/MIRI_FM_MIRIFULONG_34SHORT_DISTORTION_8B.05.02.fits',\n",
    "    'miri_devel/cdp_data/DISTORTION/MIRI_FM_MIRIFULONG_34SHORT_DISTORTION_8B.05.03.fits',\n",
    "    'miri_devel/cdp_data/DISTORTION/MIRI_FM_MIRIFUSHORT_12LONG_DISTORTION_8B.05.02.fits',\n",
    "    'miri_devel/cdp_data/DISTORTION/MIRI_FM_MIRIFUSHORT_12MEDIUM_DISTORTION_8B.05.02.fits',\n",
    "    'miri_devel/cdp_data/DISTORTION/MIRI_FM_MIRIFUSHORT_12SHORT_DISTORTION_8B.05.02.fits'\n",
    "]\n",
    "\n",
    "data_paths_full = [data_dir / p for p in data_paths]\n",
    "data_urls = [\n",
    "    'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/MRS_Mstar_analysis/spectral_leak_transmission.npy',\n",
    "    'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/MRS_Mstar_analysis/W_Per_spectrum_sws.fit',\n",
    "    'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/MRS_Mstar_analysis/jwst_miri_photom_0064.fits',\n",
    "    'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/MRS_Mstar_analysis/jwst_miri_photom_0060.fits',\n",
    "    'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/MRS_Mstar_analysis/jwst_miri_photom_0052.fits',\n",
    "    'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/MRS_Mstar_analysis/miri_devel/cdp_data/MIRI_FM_MIRIFUSHORT_2SHORT_PSF_07.02.00.fits',\n",
    "    'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/MRS_Mstar_analysis/miri_devel/cdp_data/MIRI_FM_MIRIFUSHORT_2MEDIUM_PSF_07.02.00.fits',\n",
    "    'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/MRS_Mstar_analysis/miri_devel/cdp_data/MIRI_FM_MIRIFUSHORT_2LONG_PSF_07.02.00.fits',\n",
    "    'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/MRS_Mstar_analysis/miri_devel/cdp_data/MIRI_FM_MIRIFUSHORT_1SHORT_PSF_07.02.00.fits',\n",
    "    'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/MRS_Mstar_analysis/miri_devel/cdp_data/MIRI_FM_MIRIFUSHORT_1MEDIUM_PSF_07.02.00.fits',\n",
    "    'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/MRS_Mstar_analysis/miri_devel/cdp_data/MIRI_FM_MIRIFUSHORT_1LONG_PSF_07.02.00.fits',\n",
    "    'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/MRS_Mstar_analysis/miri_devel/cdp_data/MIRI_FM_MIRIFULONG_3SHORT_PSF_07.02.00.fits',\n",
    "    'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/MRS_Mstar_analysis/miri_devel/cdp_data/MIRI_FM_MIRIFULONG_3MEDIUM_PSF_07.02.00.fits',\n",
    "    'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/MRS_Mstar_analysis/miri_devel/cdp_data/MIRI_FM_MIRIFULONG_3LONG_PSF_07.02.00.fits',\n",
    "    'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/MRS_Mstar_analysis/miri_devel/cdp_data/MIRI_FM_MIRIFULONG_4SHORT_PSF_07.02.00.fits',\n",
    "    'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/MRS_Mstar_analysis/miri_devel/cdp_data/MIRI_FM_MIRIFULONG_4MEDIUM_PSF_07.02.00.fits',\n",
    "    'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/MRS_Mstar_analysis/miri_devel/cdp_data/MIRI_FM_MIRIFULONG_4LONG_PSF_07.02.00.fits',\n",
    "    'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/MRS_Mstar_analysis/miri_devel/cdp_data/DISTORTION/MIRI_FM_MIRIFULONG_34LONG_DISTORTION_8B.05.03.fits',\n",
    "    'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/MRS_Mstar_analysis/miri_devel/cdp_data/DISTORTION/MIRI_FM_MIRIFULONG_34LONG_DISTORTION_8B.05.02.fits',\n",
    "    'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/MRS_Mstar_analysis/miri_devel/cdp_data/DISTORTION/MIRI_FM_MIRIFULONG_34MEDIUM_DISTORTION_8B.05.02.fits',\n",
    "    'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/MRS_Mstar_analysis/miri_devel/cdp_data/DISTORTION/MIRI_FM_MIRIFULONG_34MEDIUM_DISTORTION_8B.05.03.fits',\n",
    "    'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/MRS_Mstar_analysis/miri_devel/cdp_data/DISTORTION/MIRI_FM_MIRIFULONG_34SHORT_DISTORTION_8B.05.02.fits',\n",
    "    'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/MRS_Mstar_analysis/miri_devel/cdp_data/DISTORTION/MIRI_FM_MIRIFULONG_34SHORT_DISTORTION_8B.05.03.fits',\n",
    "    'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/MRS_Mstar_analysis/miri_devel/cdp_data/DISTORTION/MIRI_FM_MIRIFUSHORT_12LONG_DISTORTION_8B.05.02.fits',\n",
    "    'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/MRS_Mstar_analysis/miri_devel/cdp_data/DISTORTION/MIRI_FM_MIRIFUSHORT_12MEDIUM_DISTORTION_8B.05.02.fits',\n",
    "    'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/MRS_Mstar_analysis/miri_devel/cdp_data/DISTORTION/MIRI_FM_MIRIFUSHORT_12SHORT_DISTORTION_8B.05.02.fits'\n",
    "] \n",
    "\n",
    "for p, url in zip(data_paths_full, data_urls):\n",
    "    if os.path.exists(p):\n",
    "        print(f\"{p.name} exists.\")\n",
    "    # else:\n",
    "    #     print(f\"Downloading {p.name}...\")\n",
    "    #     urllib.request.urlretrieve(url, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Pipeline\n",
    "\n",
    "The various [stages of the pipeline](https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/main.html#pipelines) can be [run within Python](https://jwst-pipeline.readthedocs.io/en/latest/jwst/introduction.html#running-from-within-python).  For a more in depth tutorial on running the pipelines, check out the [JWebbinars](https://www.stsci.edu/jwst/science-execution/jwebbinars)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Execute calwebb_detector1 pipeline on raw simulation output.  This will overwrite previous reductions.\n",
    "\n",
    "allshortfiles = glob.glob('/data/elastic-notebook/data/spectroscopy/20210413_*_mirisim/det_images/*MIRIFUSHORT*fits')\n",
    "alllongfiles = glob.glob('/data/elastic-notebook/data/spectroscopy/20210413_*_mirisim/det_images/*MIRIFULONG*fits')\n",
    "      \n",
    "pipe1short = Detector1Pipeline()\n",
    "\n",
    "# run calwebb_detector1 on the MIRIFUSHORT data separate from MIRIFULONG data, as it saves time this way\n",
    "for shortfile in allshortfiles:\n",
    "    baseshort, remaindershort = shortfile.split('.')\n",
    "    \n",
    "    # If you run your own simulations, you will need to update these hardcoded files.\n",
    "    beforestuffshort, dateafterstuffshort = shortfile.split('20210413_')    \n",
    "    datestringshort, afterstuffshort = dateafterstuffshort.split('_mirisim')\n",
    "    \n",
    "    pipe1short.refpix.skip = True\n",
    "    pipe1short.output_file = baseshort + datestringshort\n",
    "    pipe1short.output_dir = '/data/elastic-notebook/data/spectroscopy'\n",
    "    print(pipe1short.output_file)\n",
    "\n",
    "pipe1long = Detector1Pipeline()\n",
    "\n",
    "for longfile in alllongfiles:\n",
    "    baselong, remainderlong = longfile.split('.')\n",
    "    \n",
    "    # If you run your own simulations, you will need to update these hardcoded files.\n",
    "    beforestufflong, dateafterstufflong = longfile.split('20210413_')\n",
    "    datestringlong, afterstufflong = dateafterstufflong.split('_mirisim')\n",
    "    \n",
    "    pipe1long.refpix.skip = True\n",
    "    pipe1long.output_file = baselong + datestringlong\n",
    "    pipe1long.output_dir = '/data/elastic-notebook/data/spectroscopy'\n",
    "    \n",
    "    pipe1long.run(longfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute calwebb_spec2 pipeline. This will overwrite previous reductions.\n",
    "\n",
    "# All the local calwebb_detector1 files\n",
    "allshortfiles2 = glob.glob('/data/elastic-notebook/data/spectroscopy/det_image_*_MIRIFUSHORT_*_rate.fits')\n",
    "alllongfiles2 = glob.glob('/data/elastic-notebook/data/spectroscopy/det_image_*_MIRIFULONG_*_rate.fits')\n",
    "\n",
    "print(allshortfiles2)\n",
    "print(alllongfiles2)\n",
    "\n",
    "for short2file in allshortfiles2:\n",
    "    print(short2file)\n",
    "    pipe2short = Spec2Pipeline()\n",
    "    base2short, remainder2short = short2file.split('.')\n",
    "    \n",
    "    pipe2short.straylight.skip = True\n",
    "    \n",
    "    # If you run your own simulations, you will need to update these hardcoded files.\n",
    "    if (short2file == 'det_image_seq1_MIRIFUSHORT_12LONGexp1125354_rate.fits'):\n",
    "        print('this one will have the level 2b cube built')\n",
    "    else:\n",
    "        pipe2short.cube_build.skip = True\n",
    "    pipe2short.extract_1d.skip = True\n",
    "    pipe2short.output_file = base2short\n",
    "    pipe2short.output_dir = '/data/elastic-notebook/data/spectroscopy'\n",
    "        \n",
    "    pipe2short.run(short2file)\n",
    "\n",
    "for long2file in alllongfiles2:\n",
    "    print(long2file)\n",
    "    pipe2long = Spec2Pipeline()\n",
    "    base2long, remainder2long = long2file.split('.')\n",
    "    \n",
    "    pipe2long.straylight.skip = True\n",
    "    # If you run your own simulations, you will need to update these hardcoded files.\n",
    "    if (long2file == '/data/elastic-notebook/data/spectroscopy/det_image_seq1_MIRIFULONG_34SHORTexp1120546_rate.fits'):\n",
    "        print('this one will have the level 2b cube built')\n",
    "    else:\n",
    "        pipe2long.cube_build.skip = True\n",
    "    pipe2long.extract_1d.skip = True\n",
    "    pipe2long.output_file = base2long\n",
    "    pipe2long.output_dir = '/data/elastic-notebook/data/spectroscopy'\n",
    "    \n",
    "    pipe2long.run(long2file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you run your own simulations, you will need to update these hardcoded files.\n",
    "s_cube_file = '/data/elastic-notebook/data/spectroscopy/det_image_seq1_MIRIFULONG_34SHORTexp1120546_s3d.fits'\n",
    "\n",
    "with fits.open(s_cube_file) as hdu_s_cube:\n",
    "    s_cube = hdu_s_cube['SCI'].data\n",
    "    s_med_cube = np.zeros((s_cube.shape[1], s_cube.shape[2]))\n",
    "    for a in range(s_cube.shape[1]):\n",
    "        for b in range(s_cube.shape[2]):\n",
    "            s_med_cube[a, b] = np.median(s_cube[:, a, b])\n",
    "\n",
    "mean, median, std = sigma_clipped_stats(s_med_cube, sigma=2.0)\n",
    "\n",
    "# Get a list of sources using a dedicated source detection algorithm\n",
    "# Find sources at least 3* background (typically)\n",
    "\n",
    "daofind = DAOStarFinder(fwhm=2.0, threshold=3.*std)\n",
    "sources = daofind(s_med_cube-median) \n",
    "print(\"\\n Number of sources in field: \", len(sources))\n",
    "\n",
    "# Positions in pixels\n",
    "positions = Table([sources['xcentroid'], sources['ycentroid']])\n",
    "\n",
    "# Convert to RA & Dec (ICRS)\n",
    "peakpixval = np.zeros(len(sources['xcentroid']))\n",
    "for count_s, _ in enumerate(sources):\n",
    "    peakpixval[count_s] = s_med_cube[int(np.round(sources['xcentroid'][count_s])), int(np.round(sources['ycentroid'][count_s]))]\n",
    "print('peak pixel x =')\n",
    "print(sources['xcentroid'][np.argmax(peakpixval)])\n",
    "print('peak pixel y =')\n",
    "print(sources['ycentroid'][np.argmax(peakpixval)])\n",
    "\n",
    "plt.imshow(s_med_cube, vmin=0, vmax=100)\n",
    "plt.tight_layout()\n",
    "plt.scatter(sources['xcentroid'], sources['ycentroid'], c=\"red\", marker=\"+\", s=50)\n",
    "plt.scatter(sources['xcentroid'][np.argmax(peakpixval)], sources['ycentroid'][np.argmax(peakpixval)], c='black', marker='+', s=50)\n",
    "plt.show()\n",
    "\n",
    "f0 = fits.open(s_cube_file)\n",
    "w0 = WCS(f0[('sci', 1)].header, f0)\n",
    "f0.close()\n",
    "\n",
    "radec = w0.all_pix2world([sources['xcentroid'][np.argmax(peakpixval)]], [sources['ycentroid'][np.argmax(peakpixval)]], [1], 1)\n",
    "\n",
    "# Take the brightest source flux and take that to be your primary point source for extraction\n",
    "ra_ptsrc = radec[0][0]\n",
    "dec_ptsrc = radec[1][0]\n",
    "\n",
    "del w0, WCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to the way the pipeline currently extracts Level3 data, you must update the headers to be centered on the point source of your choosing from the step above.\n",
    "all_files = glob.glob('/data/elastic-notebook/data/spectroscopy/det_image_*_cal.fits')\n",
    "targra = ra_ptsrc\n",
    "targdec = dec_ptsrc\n",
    "for thisfile in all_files:\n",
    "    base, remainder = thisfile.split('.')\n",
    "    outfilename = base + '_fix.' + remainder\n",
    "    print(outfilename)\n",
    "    \n",
    "    with fits.open(thisfile) as hduthis:\n",
    "        hduthis['SCI'].header['SRCTYPE'] = 'POINT'\n",
    "        hduthis[0].header['TARG_RA'] = targra \n",
    "        hduthis[0].header['TARG_DEC'] = targdec\n",
    "        hduthis.writeto(outfilename, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up needed reference file(s) for spec3\n",
    "\n",
    "file_all_list = glob.glob('/data/elastic-notebook/data/spectroscopy/det_image_*_cal.fits')\n",
    "\n",
    "asnall = asn_from_list.asn_from_list(file_all_list, rule=DMS_Level3_Base, product_name='combine_dithers_all_exposures')\n",
    "\n",
    "asnallfile = '/data/elastic-notebook/tmp/for_spec3_all.json'\n",
    "with open(asnallfile, 'w') as fpall:\n",
    "    fpall.write(asnall.dump()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Execute calwebb_spec3 pipeline.  This will overwrite previous reductions.\n",
    "\n",
    "pipe3ss = Spec3Pipeline()\n",
    "pipe3ss.master_background.skip = True\n",
    "pipe3ss.mrs_imatch.skip = True\n",
    "pipe3ss.outlier_detection.skip = True\n",
    "pipe3ss.resample_spec.skip = True\n",
    "pipe3ss.combine_1d.skip = True\n",
    "pipe3ss.use_source_posn = 'True'\n",
    "pipe3ss.subtract_background = 'True'\n",
    "pipe3ss.output_file = 'allspec3'\n",
    "pipe3ss.run(asnallfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now to detect the point source in the detector image plane and extract and plot the spectra for each source\n",
    "Steps involved:\n",
    "1. Convert MJy/sr to Jy\n",
    "2. Determine PSF centroid on the detector plane, if this one is not provided\n",
    "3. Based on the across-slice position of the point source, determine the transmission and wavelength correction factors and apply correction\n",
    "4. Project MRS PSF model from 3D spectral cube to 2D detector image plane\n",
    "5. Determine pixel weights based on PSF and pixel variance information\n",
    "6. Perform detector-based spectral extraction\n",
    "7. If MRS spectral band is 3A (~12.2 micron), determine diffraction grating second order spectral leak contribution (from ~6.1 microns) and apply correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# centroid placeholders in local MRS coordinates\n",
    "alpha_centers2D_dict = {}\n",
    "beta_centers2D_dict = {}\n",
    "# spectrum placeholder\n",
    "isolambda_spec_optimal = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define spectral band\n",
    "band = '1B'\n",
    "ch = band[0]\n",
    "\n",
    "if ch in ['1', '2']:\n",
    "    det_id = 'MIRIFUSHORT'\n",
    "    band_combo = '12'\n",
    "elif ch in ['3', '4']:\n",
    "    det_id = 'MIRIFULONG'\n",
    "    band_combo = '34'\n",
    "    \n",
    "if band[1] == 'A':\n",
    "    band_id = 'short'\n",
    "    band_id_nr = 1\n",
    "elif band[1] == 'B':\n",
    "    band_id = 'medium'\n",
    "    band_id_nr = 2\n",
    "elif band[1] == 'C':\n",
    "    band_id = 'long'\n",
    "    band_id_nr = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data file SCI and ERR extensions\n",
    "if band in ['1A', '2A']:\n",
    "    hdu = fits.open('/data/elastic-notebook/data/spectroscopy/det_image_seq1_MIRIFULONG_34SHORTexp1120546_cal.fits')\n",
    "    hdu_photom = fits.open('/data/elastic-notebook/data/spectroscopy/jwst_miri_photom_0052.fits')  \n",
    "elif band in ['1B', '2B']:\n",
    "    hdu = fits.open('/data/elastic-notebook/data/spectroscopy/det_image_seq1_MIRIFULONG_34MEDIUMexp1123047_cal.fits')\n",
    "    hdu_photom = fits.open('/data/elastic-notebook/data/spectroscopy/jwst_miri_photom_0064.fits')\n",
    "elif band in ['1C', '2C']:\n",
    "    hdu = fits.open('/data/elastic-notebook/data/spectroscopy/det_image_seq1_MIRIFULONG_34LONGexp1125354_cal.fits')\n",
    "    hdu_photom = fits.open('/data/elastic-notebook/data/spectroscopy/jwst_miri_photom_0060.fits')\n",
    "sci_img = hdu['SCI'].data\n",
    "err_img = hdu['ERR'].data\n",
    "\n",
    "# load photom PIXSIZ extension to convert MJy/sr to Jansky\n",
    "pixsiz_img = hdu_photom['PIXSIZ'].data\n",
    "\n",
    "# convert MJy/sr to Jansky for both the SCI and ERR extensions\n",
    "sci_img = sci_img*pixsiz_img # MJy/sr --> MJy\n",
    "err_img = err_img*pixsiz_img # MJy/sr --> MJy\n",
    "\n",
    "sci_img = sci_img*10**6 # MJy --> Jy\n",
    "err_img = err_img*10**6 # MJy --> Jy\n",
    "\n",
    "# close opened fits files\n",
    "hdu.close()\n",
    "hdu_photom.close()\n",
    "\n",
    "# Point source corrections CDP values\n",
    "# Transmission vs across-slice correction\n",
    "hdu = fits.open('/data/elastic-notebook/data/spectroscopy/miri-ifuptcor-59645.fits')\n",
    "list_channels = ['CH1', 'CH2', 'CH3', 'CH4']\n",
    "lamb_min = np.round(hdu['TRACOR'].data['WAVE_MIN'], 2)\n",
    "lamb_max = np.round(hdu['TRACOR'].data['WAVE_MAX'], 2)\n",
    "Tcen_min = np.round(hdu['TRACOR'].data['T_WMIN_CENTRE'], 2)\n",
    "Tcen_max = np.round(hdu['TRACOR'].data['T_WMAX_CENTRE'], 2)\n",
    "Tedg_min = np.round(hdu['TRACOR'].data['T_WMIN_EDGE'], 2)\n",
    "Tedg_max = np.round(hdu['TRACOR'].data['T_WMAX_EDGE'], 2)\n",
    "\n",
    "# Wavelength offset vs across-slice correction\n",
    "bands = hdu['WAVCORR_OPTICAL'].data['SUB_BAND']\n",
    "x_slice_min_LT = np.round(hdu['WAVCORR_XSLICE'].data['XSLICE_MIN'][0], 8) # micron * arcsec^-1\n",
    "x_slice_max_LT = np.round(hdu['WAVCORR_XSLICE'].data['XSLICE_MAX'][0], 8) # micron * arcsec^-1\n",
    "\n",
    "beta_slice = np.round(hdu['WAVCORR_OPTICAL'].data['BETA_SLICE'], 3)\n",
    "\n",
    "wave_min = np.round(hdu['WAVCORR_OPTICAL'].data['WAVE_MIN'], 2)\n",
    "wave_max = np.round(hdu['WAVCORR_OPTICAL'].data['WAVE_MAX'], 2)\n",
    "srp_min = hdu['WAVCORR_OPTICAL'].data['SRP_MIN']\n",
    "srp_max = hdu['WAVCORR_OPTICAL'].data['SRP_MAX']\n",
    "\n",
    "beta_off = np.round(hdu['WAVCORR_SHIFT'].data['BETA_OFF'], 3)\n",
    "Delta_s_min_LT = hdu['WAVCORR_SHIFT'].data['DS_MIN']\n",
    "Delta_s_max_LT = hdu['WAVCORR_SHIFT'].data['DS_MAX']\n",
    "\n",
    "# Spectral leak (second order spectral response in form of an optical system transmission)\n",
    "sys_transm_img = hdu['SCI'].data\n",
    "hdu.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path to distortion (D2C) files (and create folder if it doesn't exist)\n",
    "workDir = '/data/elastic-notebook/data/spectroscopy/miri_devel/'\n",
    "cdpDir = workDir+'cdp_data/'\n",
    "d2cDir = cdpDir+'DISTORTION/'\n",
    "\n",
    "# Evaluate largest distortion solution on the 2D detector (lowest slice transmission)\n",
    "d2cMaps = d2cMapping(band, d2cDir, slice_transmission='10pc', fileversion=\"8B.05.02\")\n",
    "sliceMap = d2cMaps['sliceMap']\n",
    "lambdaMap = d2cMaps['lambdaMap']\n",
    "alphaMap = d2cMaps['alphaMap']\n",
    "betaMap = d2cMaps['betaMap']\n",
    "nslices = d2cMaps['nslices']\n",
    "\n",
    "# some auxiliary data\n",
    "det_dims = (1024, 1032)\n",
    "bandlims = [lambdaMap[np.nonzero(lambdaMap)].min(), lambdaMap[np.nonzero(lambdaMap)].max()]\n",
    "\n",
    "# spectral grid based on which the point source centroid is determined\n",
    "lambmin = mrs_aux(band)[3][0]\n",
    "lambmax = mrs_aux(band)[3][1]\n",
    "lambcens = np.arange(lambmin, lambmax, (lambmax-lambmin)/1024.)\n",
    "lambfwhms = np.ones(len(lambcens))*(5*(lambmax-lambmin)/1024.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine point source centroid\n",
    "sign_amp2D, alpha_centers2D, beta_centers2D, sigma_alpha2D, sigma_beta2D, bkg_amp2D = point_source_centroiding(band, sci_img, d2cMaps, spec_grid=[lambcens, lambfwhms], fit='2D')\n",
    "\n",
    "alpha_centers2D_dict[band] = alpha_centers2D\n",
    "beta_centers2D_dict[band] = beta_centers2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic plot for the point source centroid: We care about the mean value of alpha, beta. These will be used for the PSF projection on the detector plane.\n",
    "# Conceivably a PSF residual algorithm could be coded, to determine the alpha,beta centroid more accurately still.\n",
    "fig, axs = plt.subplots(2, 1, figsize=(15, 10))\n",
    "axs[0].plot(lambcens[20:-20], alpha_centers2D_dict[band][20:-20])\n",
    "axs[0].plot(lambcens[20:-20], np.ones(len(lambcens[20:-20]))*np.mean(alpha_centers2D_dict[band][20:-20]), 'k--')\n",
    "axs[1].plot(lambcens[20:-20], beta_centers2D_dict[band][20:-20])\n",
    "axs[1].plot(lambcens[20:-20], np.ones(len(lambcens[20:-20]))*np.mean(beta_centers2D_dict[band][20:-20]), 'k--')\n",
    "axs[0].set_ylabel(r'Along-slice position $\\alpha$ [arcsec]')\n",
    "axs[0].set_title('MRS Band {}'.format(band))\n",
    "axs[1].set_xlabel(r'Wavelength [$\\mu m$]')\n",
    "axs[1].set_ylabel(r'Across-slice position $\\beta$ [arcsec]')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine transmission factor corresponding to source across-slice position $\\beta$, the signal should be multiplied by this factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = np.mean(beta_centers2D_dict[band][20:-20])\n",
    "wav_array = {}\n",
    "Tb_min = {}\n",
    "Tb_max = {}\n",
    "Tdiff_point = {}\n",
    "Tdiff_extended = {}\n",
    "for i, key in enumerate(['CH1', 'CH2', 'CH3', 'CH4']):\n",
    "    wav_array[key] = np.arange(lamb_min[i], lamb_max[i], 0.01) # micron\n",
    "    Tb_min[key] = Tcen_min[i] + 2 * abs(beta) * (Tedg_min[i]-Tcen_min[i])\n",
    "    Tb_max[key] = Tcen_max[i] + 2 * abs(beta) * (Tedg_max[i]-Tcen_max[i])\n",
    "    \n",
    "    Tdiff_point[key] = Tb_min[key] + ((wav_array[key]-lamb_min[i])/(lamb_max[i]-lamb_min[i])) * (Tb_max[key]-Tb_min[key])\n",
    "    Tdiff_extended[key] = (Tcen_min[i]+Tedg_max[i])/2. + ((wav_array[key]-lamb_min[i])/(lamb_max[i]-lamb_min[i])) * ((Tcen_max[i]+Tedg_max[i]) - (Tcen_min[i]+Tedg_min[i])) / 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 7))\n",
    "for key in ['CH1', 'CH2', 'CH3', 'CH4']:\n",
    "    plt.plot(wav_array[key], Tdiff_point[key], 'k', linestyle='dashed')\n",
    "    plt.plot(wav_array[key], Tdiff_extended[key], 'k')\n",
    "plt.xlabel(r'Wavelength [$\\mu m$]')\n",
    "plt.ylabel(r'Transmission correction [%]')\n",
    "legend_elements = [Line2D([0], [0], color='k', linestyle='dashed', label=r'Point source correction ($\\beta$ = {} arcsec)'.format(np.round(beta, 2))),\n",
    "                   Line2D([0], [0], color='k', linestyle='solid', label='Extended source correction')]\n",
    "plt.legend(handles=legend_elements, fontsize=20)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "for key in ['CH1', 'CH2', 'CH3', 'CH4']:\n",
    "    plt.plot(wav_array[key], Tdiff_point[key]/Tdiff_extended[key], 'k', linestyle='dotted')\n",
    "plt.xlabel(r'Wavelength [$\\mu m$]')\n",
    "plt.ylabel(r'$\\zeta$ = Tdiff_point / Tdiff_extended')\n",
    "legend_elements = [Line2D([0], [0], color='k', linestyle='dotted', label=r'$\\beta$ = {} arcsec'.format(np.round(beta, 2)))]\n",
    "plt.legend(handles=legend_elements)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'CH' + band[0]\n",
    "ip_zeta = interp1d(wav_array[key], Tdiff_point[key]/Tdiff_extended[key], kind='linear')\n",
    "\n",
    "zetaMap = np.ones(lambdaMap.shape)\n",
    "sel = (sliceMap > 100*int(band[0])) & (sliceMap < 100*(int(band[0]) + 1))\n",
    "zetaMap[sel] = ip_zeta(lambdaMap[sel])\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(zetaMap, vmin=zetaMap[zetaMap != 0].min(), vmax=zetaMap[zetaMap != 0].max())\n",
    "clb = plt.colorbar()\n",
    "clb.set_label(r'$\\zeta$')\n",
    "plt.xlabel('X-pixel')\n",
    "plt.ylabel('Y-pixel')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply correction to science and error signal\n",
    "sci_img *= zetaMap\n",
    "err_img *= zetaMap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine wavelength correction due to source across-slice position $\\beta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_center = np.mean(beta_centers2D_dict[band][20:-20])\n",
    "\n",
    "# determine unique beta values for each slice\n",
    "sel = np.where((sliceMap > 100*int(band[0])) & (sliceMap < 100*(int(band[0])+1)))\n",
    "unique_betas = np.unique(betaMap[sel])\n",
    "\n",
    "# find index of value nearest to beta center in the unique_betas array\n",
    "idx = np.abs(unique_betas-beta_center).argmin() \n",
    "source_center_slice = idx+1\n",
    "\n",
    "# find index of value nearest to beta center in the unique_betas array\n",
    "beta_brightest_slice = unique_betas[idx]\n",
    "\n",
    "# Point source offset from slice centre (-0.5 < tgtOffset < +0.5)\n",
    "betaOffsetSlice0 = (beta_center-beta_brightest_slice)/d2cMaps['bdel'] \n",
    "\n",
    "# Define input data characteristics.\n",
    "nSubBands = 3\n",
    "optIndex = nSubBands * (int(band[0]) - 1) + (band_id_nr - 1)\n",
    "betaSlice = beta_slice[optIndex]\n",
    "\n",
    "# Compute wavelength correction map (based on MIRI-DD-00006-ATC issue 4)\n",
    "# The correction is valid only for the two slices nearest to the brightest slice\n",
    "wavcorr_across_slice = np.zeros((1024, 1032))\n",
    "for islice in range(-2, 3):\n",
    "    sel = (sliceMap == 100*int(band[0])+source_center_slice+islice)\n",
    "    tgtWave = lambdaMap[sel]\n",
    "    \n",
    "    # Step 1. Find target offset from slice centre in beta direction'\n",
    "    betaOff = betaOffsetSlice0 - islice\n",
    "\n",
    "    # Step 2. Calculate Xslice\n",
    "    xSlice = betaSlice / tgtWave\n",
    "    xSliceref = betaSlice / ((lambmin+lambmax)/2.) # We define a reference xslice for the entire band to avoid jumps between beta_off values as a function of wavelength in Step 4.\n",
    "\n",
    "    # Step 3. Derive scaled offset\n",
    "    betaOff_scaled = betaOff * xSlice\n",
    "    betaOff_scaled_ref = betaOff * xSliceref  # We define a reference betaOff_scaled_ref for the entire band to avoid jumps between beta_off values as a function of wavelength in Step 4.\n",
    "\n",
    "    # Step 4. Find look-up table betaOff_LT values which bracket betaOFF_scaled\n",
    "    nShiftValues = len(beta_off)\n",
    "    betaSign = 1\n",
    "    if (betaOff < 0.0):\n",
    "        betaSign = -1\n",
    "        betaOff_scaled = -1.0 * betaOff_scaled\n",
    "    indexA = -1 # Index in look up table_WCORR_SHIFT \n",
    "    for j in range(nShiftValues):\n",
    "        if (betaOff_scaled_ref < beta_off[j]):\n",
    "            if (indexA == -1):\n",
    "                indexA = j-1\n",
    "    indexB = indexA + 1\n",
    "    betaOff_LT_A = beta_off[indexA]\n",
    "    betaOff_LT_B = beta_off[indexB]\n",
    "\n",
    "    # Step 5. Find ds_min and ds_max\n",
    "    betaFactor = (betaOff_scaled - betaOff_LT_A) / (betaOff_LT_B - betaOff_LT_A) \n",
    "\n",
    "    ds_minA = Delta_s_min_LT[indexA]\n",
    "    ds_minB = Delta_s_min_LT[indexB]\n",
    "    ds_min = ds_minA + betaFactor * (ds_minB - ds_minA)\n",
    "    ds_min = betaSign * ds_min\n",
    "\n",
    "    ds_maxA = Delta_s_max_LT[indexA]\n",
    "    ds_maxB = Delta_s_max_LT[indexA]\n",
    "    ds_max = ds_maxA + betaFactor * (ds_maxB - ds_maxA)\n",
    "    ds_max = betaSign * ds_max\n",
    "\n",
    "    # Step 6. Find ds by interpolation between ds_min and ds_max\n",
    "    xSlice_min = x_slice_min_LT\n",
    "    xSlice_max = x_slice_max_LT\n",
    "    xFactor = (xSlice - xSlice_min) / (xSlice_max - xSlice_min)\n",
    "\n",
    "    ds = ds_min + xFactor * (ds_max - ds_min)\n",
    "\n",
    "    # Step 7. Convert ds to wavelength shift by intepolstion between SRP values\n",
    "    w_min = wave_min[optIndex]\n",
    "    w_max = wave_max[optIndex]\n",
    "    wFactor = (tgtWave - w_min) / (w_max - w_min)\n",
    "\n",
    "    srp = srp_min[optIndex] + wFactor * (srp_max[optIndex] - srp_min[optIndex])\n",
    "\n",
    "    wavcorr_across_slice[sel] = ds * tgtWave / srp\n",
    "\n",
    "# Plot wavelength correction map\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(wavcorr_across_slice)\n",
    "clb = plt.colorbar()\n",
    "clb.set_label('Wavelength correction [$\\u03bc m$]')\n",
    "plt.xlabel('X-pixel')\n",
    "plt.ylabel('Y-pixel')\n",
    "plt.title('MRS spectral band {}'.format(band))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply correction to wavelength map\n",
    "lambdaMap += wavcorr_across_slice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load MRS PSF model in the 3D spectral cube and project it on the 2D detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psf_fits_file = cdpDir+\"MIRI_FM_{}_{}{}_PSF_07.02.00.fits\".format(det_id, ch, band_id.upper())\n",
    "psffits = fits.open(psf_fits_file)\n",
    "\n",
    "# normalize and project PSF on 2D detector (normalization ensures that each cube slice of the model has a signal sum of 1)\n",
    "psf_img = evaluate_psf_cdp(psffits, d2cMaps, source_center=[np.mean(alpha_centers2D_dict[band][20:-20]), np.mean(beta_centers2D_dict[band][20:-20])], norm=True)\n",
    "\n",
    "# close fits file\n",
    "psffits.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic plot to show how well the projected PSF matches the data\n",
    "# For low SNR observations this will likely not be very useful\n",
    "plt.close('all')\n",
    "plt.figure(figsize=(16, 6))\n",
    "if band[0] in ['1', '4']:\n",
    "    plt.plot(sci_img[512, 10:516], label='MIRISim signal')\n",
    "    scale_factor = (sci_img[512, 10:516][~np.isnan(sci_img[512, 10:516])].max()/psf_img[512, 10:516].max())\n",
    "    plt.plot(psf_img[512, 10:516]*scale_factor, label='PSF model (scaled)')\n",
    "elif band[0] in ['2', '3']:\n",
    "    plt.plot(sci_img[512, 516:-10], label='MIRISim signal')\n",
    "    scale_factor = (sci_img[512, 516:-10][~np.isnan(sci_img[512, 516:-10])].max()/psf_img[512, 516:-10].max())\n",
    "    plt.plot(psf_img[512, 516:-10]*scale_factor, label='PSF model (scaled)')\n",
    "plt.xlabel('X-pixel')\n",
    "plt.ylabel('Signal [DN/sec]')\n",
    "plt.legend()\n",
    "plt.title('MRS spectral band {}'.format(band))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine optimal pixel weights for detector-based spectral extraction\n",
    "weight_map = psf_img**2 / (err_img)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wavelength array used for the detector-based spectral extraction\n",
    "# The grid step is approximately half the smallest spectral size in each band (due to the MRS distortion and slice curvature, different pixels contribute to each bin)\n",
    "wav_array = {'1A': np.arange(4.9, 5.74, 0.0005), '1B': np.arange(5.67, 6.6, 0.0008), '1C': np.arange(6.45, 7.5, 0.001),\n",
    "             '2A': np.arange(7.477, 8.765, 0.0014), '2B': np.arange(8.711, 10.228, 0.0017), '2C': np.arange(10.017, 11.753, 0.002),\n",
    "             '3A': np.arange(11.481, 13.441, 0.0023), '3B': np.arange(13.319, 15.592, 0.0026), '3C': np.arange(15.4, 18.072, 0.0030),\n",
    "             '4A': np.arange(17.651, 20.938, 0.0036), '4B': np.arange(20.417, 24.22, 0.0042), '4C': np.arange(23.884, 28.329, 0.0048)}\n",
    "nwavs = len(wav_array[band])\n",
    "\n",
    "# Evaluate smallest distortion solution on the 2D detector (largest slice transmission of 90%)\n",
    "slice_transmission = '90pc'\n",
    "d2cMaps = d2cMapping(band, d2cDir, slice_transmission=slice_transmission, fileversion=\"8B.05.02\")\n",
    "lambdaMap = d2cMaps['lambdaMap']\n",
    "lambdas = lambdaMap[np.nonzero(lambdaMap)].flatten()\n",
    "\n",
    "# Need approximate number of pixels contributing to each spectral bin\n",
    "# This is because only one pixel is used for each detector column --> we want to avoid sampling issues\n",
    "if band[0] in ['1', '2']:\n",
    "    if slice_transmission == '90pc':\n",
    "        npix = 380\n",
    "    elif slice_transmission == '10pc':\n",
    "        npix = 500\n",
    "elif band[0] in ['3', '4']:\n",
    "    npix = 380\n",
    "k = np.arange(npix)\n",
    "\n",
    "# Define pixel grid\n",
    "X, Y = np.meshgrid(np.arange(1032), np.arange(1024))\n",
    "X_flat = X[np.nonzero(lambdaMap)].flatten()\n",
    "Y_flat = Y[np.nonzero(lambdaMap)].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Omit NaNs from analysis\n",
    "nan_idx = ~np.isnan(sci_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diffraction grating second order spectral leak contribution\n",
    "if band == '1B':\n",
    "    \n",
    "    np.save('/data/elastic-notebook/tmp/spectral_leak_transmission.npy', sys_transm_img)\n",
    "    \n",
    "    plt.close('all')\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(sys_transm_img*100.)\n",
    "    clb = plt.colorbar()\n",
    "    clb.set_label('Dichroic transmission [%]')\n",
    "    plt.xlabel('X-pixel')\n",
    "    plt.ylabel('Y-pixel')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Compute spectral leak signal from band 1B and update the error map\n",
    "    spectral_leak_sci_img = sci_img*sys_transm_img\n",
    "    spectral_leak_err_img = err_img*sys_transm_img\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(spectral_leak_sci_img*1000)\n",
    "    clb = plt.colorbar()\n",
    "    clb.set_label('Spectral leak signal [mJy]')\n",
    "    plt.xlabel('X-pixel')\n",
    "    plt.ylabel('Y-pixel')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Redetermine optimal pixel weights for detector-based spectral extraction\n",
    "    spectral_leak_weight_map = psf_img**2 / (spectral_leak_err_img)**2\n",
    "    \n",
    "    # Initialize placeholder\n",
    "    spectral_leak_spectrum = np.zeros(nwavs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform detector-based spectral extraction\n",
    "isolambda_spec_optimal[band] = np.zeros(nwavs)\n",
    "\n",
    "for i in range(nwavs):\n",
    "    # determine pixels contributing to spectral bin\n",
    "    test_img = np.zeros((1024, 1032))\n",
    "    idxs = np.argsort(np.abs(lambdas-wav_array[band][i]))[k]\n",
    "    test_img[Y_flat[idxs], X_flat[idxs]] = 1\n",
    "    \n",
    "    # ascertain that only one pixel is selected per detector column\n",
    "    outliers = np.where(np.sum(test_img, axis=0) == 2)[0]\n",
    "\n",
    "    for col in outliers:\n",
    "        Y_ = np.argsort(np.abs(lambdaMap[:, col] - wav_array[band][i]))[1]\n",
    "        test_img[Y_, col] = 0\n",
    "    \n",
    "    # plot meant for debugging !!!ONLY USE AT A SINGLE WAVELENGTH!!!\n",
    "    # plt.figure()\n",
    "    # plt.imshow(test_img,aspect=0.5)\n",
    "    # plt.tight_layout()\n",
    "\n",
    "    # spectral extraction\n",
    "    sel_valid = (test_img == 1) & nan_idx\n",
    "    isolambda_spec_optimal[band][i] = np.sum(weight_map[sel_valid] * sci_img[sel_valid] / psf_img[sel_valid]) / np.sum(weight_map[sel_valid])\n",
    "    \n",
    "    if band == '1B':\n",
    "        # Estimate diffraction grating second order spectral leak contribution\n",
    "        spectral_leak_spectrum[i] = np.sum(spectral_leak_weight_map[sel_valid] * spectral_leak_sci_img[sel_valid] / psf_img[sel_valid]) / np.sum(spectral_leak_weight_map[sel_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debugging spectral bins\n",
    "\n",
    "i = 200\n",
    "# determine pixels contributing to spectral bin\n",
    "test_img = np.zeros((1024, 1032))\n",
    "idxs = np.argsort(np.abs(lambdas-wav_array[band][i]))[k]\n",
    "test_img[Y_flat[idxs], X_flat[idxs]] = 1\n",
    "\n",
    "# ascertain that only one pixel is selected per detector column\n",
    "outliers = np.where(np.sum(test_img, axis=0) == 2)[0]\n",
    "\n",
    "for col in outliers:\n",
    "    Y_ = np.argsort(np.abs(lambdaMap[:, col]-wav_array[band][i]))[1]\n",
    "    test_img[Y_, col] = 0\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(test_img)\n",
    "plt.imshow(d2cMaps['sliceMap'], alpha=0.4)\n",
    "plt.xlabel('X-pixel')\n",
    "plt.ylabel('Y-pixel')\n",
    "plt.title('MRS spectral band {}'.format(band))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct for spectral leak if MRS band is set to 3A\n",
    "## CAUTION: In order for the following cell to work, the user must have run this notebook already once for band 1B."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE END\n",
    "\n",
    "## Still to do:\n",
    "- Loop the notebook over all dither positions and average the resulting spectra. The reason why we may not want to use all four dithers in one go (i.e. to run the detector based extraction only once) is because we will likely find variations in the PSF as a function of which slice gets illuminated on the detector (think incoming cone angle and detector-scattered light).\n",
    "- Consider updating current centroiding algorithm to use the cross-correlation method of the SDSS MANGA pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## About this notebook\n",
    "**Author:** Ioannis (Yannis) Argyriou, Post-Doctoral Researcher, Institute of Astronomy, KU Leuven, Belgium  \n",
    "**Date:** 2022-01-08"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#top)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
