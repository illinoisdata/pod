{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/elastic-notebook/data/fashion-mnist/2020-mpcs53111-hw5-fashionmnist.zip\n",
      "/data/elastic-notebook/data/fashion-mnist/fashionmnist_test.npy\n",
      "/data/elastic-notebook/data/fashion-mnist/fashionmnist_train.npy\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/data/elastic-notebook/data/fashion-mnist'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dataset_prefix = \"fashionmnist\" \n",
    "\n",
    "train_data = np.load(\"/data/elastic-notebook/data/fashion-mnist/{}_train.npy\".format(dataset_prefix))\n",
    "test_data = np.load(\"/data/elastic-notebook/data/fashion-mnist/{}_test.npy\".format(dataset_prefix))\n",
    "\n",
    "train_images = train_data[:, :-1].reshape(-1, 1, 28, 28)\n",
    "train_labels = train_data[:, -1]\n",
    "test_images = test_data.reshape(-1, 1, 28, 28)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from PIL import Image\n",
    "\n",
    "pil_images = [Image.fromarray((image.reshape(image.shape[1:])*255).astype(\"uint8\"), 'L') for image in train_images]\n",
    "def pil_to_np(images):\n",
    "    images = np.array([np.array(image) for image in images])\n",
    "    return images.reshape(-1, 1, 28, 28)/255.\n",
    "modified_images = [torchvision.transforms.functional.hflip(image) for image in pil_images]\n",
    "train_images = np.concatenate([train_images, pil_to_np(modified_images)], axis=0)\n",
    "modified_images = [torchvision.transforms.functional.affine(image, 0, (-2, 0), 1, 0) for image in pil_images]\n",
    "train_images = np.concatenate([train_images, pil_to_np(modified_images)], axis=0)\n",
    "modified_images = [torchvision.transforms.functional.affine(image, 0, (+2, 0), 1, 0) for image in pil_images]\n",
    "train_images = np.concatenate([train_images, pil_to_np(modified_images)], axis=0)\n",
    "#modified_images = [torchvision.transforms.functional.affine(image, 0, (0, -2), 1, 0) for image in pil_images]\n",
    "#train_images = np.concatenate([train_images, pil_to_np(modified_images)], axis=0)\n",
    "#modified_images = [torchvision.transforms.functional.affine(image, 0, (0, +2), 1, 0) for image in pil_images]\n",
    "#train_images = np.concatenate([train_images, pil_to_np(modified_images)], axis=0)\n",
    "modified_images = None\n",
    "pil_images = None\n",
    "train_labels = np.concatenate([train_labels]*4, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils as utils\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout2d(p=0.2),\n",
    "            nn.Conv2d(128, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout2d(p=0.2),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 512, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout2d(p=0.2),\n",
    "        )\n",
    "        self.linear_layers = nn.Sequential(\n",
    "            nn.Linear(4608, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.cnn_layers(x).view(x.shape[0], -1)\n",
    "        return self.linear_layers(x1)\n",
    "\n",
    "class Model:\n",
    "    def fit(self, X, y, lr=0.001, n_epochs=50, test_data=None):\n",
    "        self.net = Net()\n",
    "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        self.net = self.net.to(self.device)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.Adam(self.net.parameters(), lr=lr)\n",
    "        train_data = (X, y)\n",
    "        X = torch.from_numpy(X).float().to(self.device)\n",
    "        y = torch.from_numpy(y).long().to(self.device)\n",
    "        data = utils.data.TensorDataset(X, y)\n",
    "        data_loader = utils.data.DataLoader(data, batch_size=512, shuffle=True)\n",
    "        for ep in range(n_epochs):\n",
    "            self.net.train()\n",
    "            for batch_X, batch_y in data_loader:\n",
    "                self.optimizer.zero_grad()\n",
    "                y_hat = self.net(batch_X)\n",
    "                loss = self.loss(y_hat, batch_y)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "            if ep % 1 == 0:\n",
    "                print(f'Epoch: {ep}, Loss: {loss}')\n",
    "                print(f'Train Accuracy: {self.score(*train_data)}')\n",
    "                if test_data: print(f'Test Accuracy: {self.score(*test_data)}')\n",
    "    def predict(self, X):\n",
    "        with torch.no_grad():\n",
    "            self.net.eval()\n",
    "            X = torch.from_numpy(X).float().to(self.device)\n",
    "            data = utils.data.TensorDataset(X)\n",
    "            data_loader = utils.data.DataLoader(data, batch_size=512)\n",
    "            outputs = []\n",
    "            for batch, in data_loader:\n",
    "                outputs.append(self.net(batch))\n",
    "            out = torch.cat(outputs)\n",
    "            return torch.argmax(out, axis=1)\n",
    "    def score(self, X, y):\n",
    "        y_hat = self.predict(X)\n",
    "        y = torch.from_numpy(y).long().to(self.device)\n",
    "        return int((y == y_hat).sum())/y.shape[0]\n",
    "    def get_params(self, deep=True): return {}\n",
    "    def set_params(self, **__): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/srv/local/data/elastic-notebook/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_4063386/2550561381.py\", line 2, in <module>\n",
      "    model.fit(train_images, train_labels)\n",
      "  File \"/tmp/ipykernel_4063386/199982349.py\", line 66, in fit\n",
      "    loss.backward()\n",
      "  File \"/srv/local/data/elastic-notebook/venv/lib/python3.8/site-packages/torch/_tensor.py\", line 396, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
      "  File \"/srv/local/data/elastic-notebook/venv/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 173, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/local/data/elastic-notebook/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 1997, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/srv/local/data/elastic-notebook/venv/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1112, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/srv/local/data/elastic-notebook/venv/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1006, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/srv/local/data/elastic-notebook/venv/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 859, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/srv/local/data/elastic-notebook/venv/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 812, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "  File \"/srv/local/data/elastic-notebook/venv/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 730, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "  File \"/srv/local/data/elastic-notebook/venv/lib/python3.8/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/srv/local/data/elastic-notebook/venv/lib/python3.8/site-packages/stack_data/core.py\", line 720, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/srv/local/data/elastic-notebook/venv/lib/python3.8/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/srv/local/data/elastic-notebook/venv/lib/python3.8/site-packages/stack_data/core.py\", line 663, in included_pieces\n",
      "    scope_pieces = self.scope_pieces\n",
      "  File \"/srv/local/data/elastic-notebook/venv/lib/python3.8/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/srv/local/data/elastic-notebook/venv/lib/python3.8/site-packages/stack_data/core.py\", line 600, in scope_pieces\n",
      "    scope_start, scope_end = self.source.line_range(self.scope)\n",
      "  File \"/srv/local/data/elastic-notebook/venv/lib/python3.8/site-packages/stack_data/core.py\", line 164, in line_range\n",
      "    return line_range(self.asttext(), node)\n",
      "AttributeError: 'Source' object has no attribute 'asttext'\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "model.fit(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.predict(test_images)\n",
    "import csv\n",
    "with open(f'/data/elastic-notebook/tmp/{dataset_prefix}_out.csv', mode='w', newline='') as out_file:\n",
    "    fieldnames = ['Id', 'Category']\n",
    "    writer = csv.DictWriter(out_file, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    for i, j in enumerate(out):\n",
    "        writer.writerow({'Id': i, 'Category': int(j)})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
