{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import os\n","import datetime\n","import numpy as np\n","import pandas as pd\n","import time\n","import lightgbm as lgb\n","from sklearn.metrics import mean_squared_error\n","from tqdm.notebook import tqdm\n","\n","path = 'nbdata/data/covid-forecasting-w3/'\n","train = pd.read_csv(path + 'train.csv')\n","test  = pd.read_csv(path + 'test.csv')\n","sub   = pd.read_csv(path + 'submission.csv')\n","\n","train['Date'] = pd.to_datetime(train['Date'])\n","test['Date'] = pd.to_datetime(test['Date'])\n","#path_ext = '../input/novel-corona-virus-2019-dataset/'\n","#ext_rec = pd.read_csv(path_ext + 'time_series_covid_19_recovered.csv').\\\n","#        melt(id_vars=[\"Province/State\", \"Country/Region\", \"Lat\", \"Long\"], \n","#            var_name=\"Date\", \n","#            value_name=\"Recoveries\")\n","#ext_rec['Date'] = ext_rec['Date'].apply(lambda x: (datetime.datetime.strptime(x+\"20\", '%m/%d/%Y')))\n","#train = train.merge(ext_rec[['Province/State', 'Country/Region', 'Date', 'Recoveries']], how='left',\n","#           left_on=['Province/State', 'Country/Region', 'Date'],\n","#           right_on=['Province/State', 'Country/Region', 'Date'])\n","\n","# print((train['Date'].dt.date - train['Date'].dt.date.min()))\n","train['days'] = (train['Date'].dt.date - train['Date'].dt.date.min()).apply(lambda x: x.days)\n","test['days'] = (test['Date'].dt.date - train['Date'].dt.date.min()).apply(lambda x: x.days)\n","#train['isTest'] = train['Date'].dt.date >= datetime.date(2020, 3, 12)\n","#train['isVal'] = np.logical_and(train['Date'].dt.date >= datetime.date(2020, 3, 11), train['Date'].dt.date <= datetime.date(9999, 3, 18))\n","train.loc[train['Province_State'].isnull(), 'Province_State'] = 'N/A'\n","test.loc[test['Province_State'].isnull(), 'Province_State'] = 'N/A'\n","\n","train['Area'] = train['Country_Region'] + '_' + train['Province_State']\n","test['Area'] = test['Country_Region'] + '_' + test['Province_State']\n","\n","print(train['Date'].max())\n","print(test['Date'].min())\n","print(train['days'].max())\n","N_AREAS = train['Area'].nunique()\n","AREAS = np.sort(train['Area'].unique())\n","#TRAIN_N = 64\n","TRAIN_N = 77\n","\n","print(train[train['days'] < TRAIN_N]['Date'].max())\n","print(train[train['days'] >= TRAIN_N]['Date'].min())\n","print(train[train['days'] >= TRAIN_N]['Date'].max())\n","train.head()\n","\n","test_orig = test.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_p_c_raw = train.pivot(index='Area', columns='days', values='ConfirmedCases').sort_index()\n","train_p_f_raw = train.pivot(index='Area', columns='days', values='Fatalities').sort_index()\n","\n","train_p_c = np.maximum.accumulate(train_p_c_raw, axis=1)\n","train_p_f = np.maximum.accumulate(train_p_f_raw, axis=1)\n","\n","f_rate = (train_p_f / train_p_c).fillna(0)\n","\n","X_c = np.log(1+train_p_c.values)[:,:TRAIN_N]\n","X_f = train_p_f.values[:,:TRAIN_N]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import mean_squared_error\n","\n","def eval1(y, p):\n","    val_len = y.shape[1] - TRAIN_N\n","    return np.sqrt(mean_squared_error(y[:, TRAIN_N:TRAIN_N+val_len].flatten(), p[:, TRAIN_N:TRAIN_N+val_len].flatten()))\n","\n","def run_c(params, X, test_size=50):\n","    \n","    gr_base = []\n","    gr_base_factor = []\n","    \n","    x_min = np.ma.MaskedArray(X, X<1)\n","    x_min = x_min.argmin(axis=1) \n","    \n","    for i in range(X.shape[0]):\n","        temp = X[i,:]\n","        threshold = np.log(1+params['min cases for growth rate'])\n","        num_days = params['last N days']\n","        if (temp > threshold).sum() > num_days:\n","            d = np.diff(temp[temp > threshold])[-num_days:]\n","            w = np.arange(len(d))+1\n","            w = w**5\n","            w = w / np.sum(w)\n","            gr_base.append(np.clip(np.average(d, weights=w), 0, params['growth rate max']))\n","            d2 = np.diff(d)\n","            w = np.arange(len(d2))+1\n","            w = w**10\n","            w = w / np.sum(w)\n","            gr_base_factor.append(np.clip(np.average(d2, weights=w), -0.5, params[\"growth rate factor max\"]))\n","        else:\n","            gr_base.append(params['growth rate default'])\n","            gr_base_factor.append(params['growth rate factor'])\n","\n","    gr_base = np.array(gr_base)\n","    gr_base_factor = np.array(gr_base_factor)\n","    #print(gr_base_factor)\n","    #gr_base = np.clip(gr_base, 0.02, 0.8)\n","    preds = X.copy()\n","\n","    for i in range(test_size):\n","        delta = np.clip(preds[:, -1], np.log(2), None) + gr_base * (1 + params['growth rate factor']*(1 + params['growth rate factor factor'])**(i))**(np.log1p(i))\n","        #delta = np.clip(preds[:, -1], np.log(2), None) + gr_base * (1 + gr_base_factor*(1 + params['growth rate factor factor'])**(i))**(i)\n","        #delta = np.clip(preds[:, -1], np.log(2), None) + gr_base * (1 + params['growth rate factor']*(1 + params['growth rate factor factor'])**(i+X.shape[1]-x_min))**(i+X.shape[1]-x_min) \n","        preds = np.hstack((preds, delta.reshape(-1,1)))\n","\n","    return preds\n","\n","params = {\n","    \"min cases for growth rate\": 0,\n","    \"last N days\": 15,\n","    \"growth rate default\": 0.10,\n","    \"growth rate max\": 0.2,\n","    \"growth rate factor max\": -0.1,\n","    \"growth rate factor\": -0.3,\n","    \"growth rate factor factor\": 0.01,\n","}\n","#x = train_p_c[train_p_c.index==\"Austria_N/A\"]\n","\n","x = train_p_c\n","\n","preds_c = run_c(params, np.log(1+x.values)[:,:TRAIN_N])\n","#eval1(np.log(1+x).values, preds_c)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","for i in range(N_AREAS):\n","    if 'China' in AREAS[i] and preds_c[i, TRAIN_N-1] < np.log(31):\n","        preds_c[i, TRAIN_N:] = preds_c[i, TRAIN_N-1]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def lin_w(sz):\n","    res = np.linspace(0, 1, sz+1, endpoint=False)[1:]\n","    return np.append(res, np.append([1], res[::-1]))\n","\n","\n","def run_f(params, X_c, X_f, X_f_r, test_size=50):\n","  \n","    X_f_r = np.array(np.ma.mean(np.ma.masked_outside(X_f_r, 0.03, 0.5)[:,:], axis=1))\n","    X_f_r = np.clip(X_f_r, params['fatality_rate_lower'], params['fatality_rate_upper'])\n","    #print(X_f_r)\n","    \n","    X_c = np.clip(np.exp(X_c)-1, 0, None)\n","    preds = X_f.copy()\n","    #print(preds.shape)\n","    \n","    train_size = X_f.shape[1] - 1\n","    for i in range(test_size):\n","        \n","        t_lag = train_size+i-params['length']\n","        t_wsize = 5\n","        d = np.diff(X_c, axis=1)[:, t_lag-t_wsize:t_lag+1+t_wsize]\n","#         w = np.arange(d.shape[1])[::-1]+1\n","#         w = w**1\n","#         w = w / np.sum(w)\n","        delta = np.average(d, axis=1)\n","        #delta = np.average(np.diff(X_c, axis=1)[:, t_lag-t_wsize:t_lag+1+t_wsize], axis=1, weights=lin_w(t_wsize))\n","        \n","        delta = params['absolute growth'] + delta * X_f_r\n","        \n","        preds = np.hstack((preds, preds[:, -1].reshape(-1,1) + delta.reshape(-1,1)))\n","\n","    return preds\n","\n","params = {\n","    \"length\": 7,\n","    \"absolute growth\": 0.02,\n","    \"fatality_rate_lower\": 0.02,\n","    \"fatality_rate_upper\": 0.3,\n","}\n","\n","preds_f_1 = run_f(params, preds_c, X_f, f_rate.values[:,:TRAIN_N])\n","preds_f_1 = np.log(1+preds_f_1)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from torch.utils.data import Dataset\n","from torch.nn import Parameter\n","import torch.nn as nn\n","from torch.nn import init\n","import math \n","import torch\n","import time\n","\n","class ZDatasetF(Dataset):\n","    def __init__(self, X_c, X_f=None, hist_len=10):\n","        self.X_c = X_c\n","        self.X_f = X_f\n","        self.hist_len = hist_len\n","        self.is_test = X_f is None\n","    def __len__(self):\n","        return self.X_c.shape[1]\n","    def __getitem__(self, idx):\n","        if self.is_test:\n","            return {'x_c':self.X_c[:, idx-self.hist_len:idx]}\n","        else:\n","            return {'x_c':self.X_c[:, idx-self.hist_len:idx],\n","                    'x_f':self.X_f[:, idx-1],\n","                    'y':np.log(1+self.X_f[:, idx])}\n","\n","class PrLayer2(nn.Module):\n","    def __init__(self, in_features1, in_features2):\n","        super(PrLayer2, self).__init__()\n","        self.weight0 = Parameter(torch.Tensor(1, 1, in_features2))\n","        self.weight1 = Parameter(torch.Tensor(1, in_features1, in_features2))\n","        self.reset_parameters()\n","    def reset_parameters(self):\n","        init.kaiming_uniform_(self.weight0, a=math.sqrt(5))\n","        init.kaiming_uniform_(self.weight1, a=math.sqrt(5))\n","    def forward(self, input):\n","        return input * torch.sigmoid(self.weight0 + self.weight1)\n","\n","\n","\n","class ZModelF(nn.Module):\n","\n","    def __init__(self, hist_len):\n","        super(ZModelF, self).__init__()\n","        self.l_conv = PrLayer2(len(X_c),hist_len-1)\n","\n","    def forward(self, x_c, x_f):\n","        x = x_c[:,:,1:] - x_c[:,:,:-1]\n","        res = torch.sum(self.l_conv(x), 2)\n","        return {'preds': torch.log(1 + x_f + res)}        \n","        \n","\n","class DummySampler(torch.utils.data.sampler.Sampler):\n","    def __init__(self, idx):\n","        self.idx = idx\n","    def __iter__(self):\n","        return iter(self.idx)\n","    def __len__(self):\n","        return len(self.idx)\n","    \n","    \n","def _smooth_l1_loss(target):\n","    t = torch.abs(target)\n","    t = torch.where(t < 1, 0.5 * t ** 2, t - 0.5)\n","    return torch.mean(t)\n","\n","\n","n_epochs = 5000\n","lr = 0.18\n","bag_size = 4\n","device = 'cpu'\n","hist_len = 14\n","loss_func = torch.nn.MSELoss()\n","reg_loss_func = _smooth_l1_loss\n","reg_factor = 0.035\n","\n","\n","train_dataset = ZDatasetF(np.exp(X_c)-1, X_f, hist_len=hist_len)\n","test_dataset = ZDatasetF(np.exp(preds_c)-1, hist_len=hist_len)\n","\n","#trn_idx = np.arange(hist_len+1, len(train_dataset))\n","trn_idx = np.arange(hist_len+1, len(train_dataset))\n","train_sampler = torch.utils.data.sampler.SubsetRandomSampler(trn_idx)\n","#train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1, sampler=train_sampler, num_workers=0, pin_memory=True)\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=len(trn_idx), sampler=train_sampler, num_workers=0, pin_memory=True)\n","\n","test_idx = np.arange(TRAIN_N, len(test_dataset))\n","test_sampler = DummySampler(test_idx)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, sampler=test_sampler, num_workers=0, pin_memory=True)\n","\n","\n","#gradient_accumulation = len(trn_idx)\n","gradient_accumulation = 1\n","\n","preds_f = 0\n","\n","for m_i in range(bag_size):\n","    model_f = ZModelF(hist_len=hist_len).to(device)\n","    optimizer_f = torch.optim.Adam(model_f.parameters(), lr=lr)\n","    model_f.train()\n","\n","    start_time = time.time()\n","    for epoch in range(n_epochs):\n","\n","        s = time.time()\n","        avg_train_loss = 0\n","        \n","        optimizer_f.zero_grad()\n","        for idx, data in enumerate(train_loader):\n","\n","            X1 = data['x_c'].to(device).float()\n","            X2 = data['x_f'].to(device).float()\n","            y = data['y'].to(device).float()\n","            \n","            preds = model_f(X1, X2)['preds'].float()\n","\n","            cond = X2 > np.log(10)\n","            preds = preds[cond]\n","            y = y[cond]\n","            \n","            loss = loss_func(preds, y)\n","            \n","            loss += reg_factor * reg_loss_func(model_f.l_conv.weight1)\n","            \n","            avg_train_loss += loss  / len(train_loader)\n","            \n","            loss.backward()\n","            if (idx+1) % gradient_accumulation == 0 or idx == len(train_loader) - 1: \n","                optimizer_f.step()\n","                optimizer_f.zero_grad()\n","                \n","        #if epoch % 1000 == 0:\n","        if False:\n","        \n","            model_f.eval()\n","            preds_f_delta = train_p_f.values[:,:TRAIN_N]\n","\n","            for idx, data in enumerate(test_loader):\n","                X1 = data['x_c'].to(device).float()\n","                temp = model_f(X1, torch.Tensor(preds_f_delta[:,-1]).unsqueeze(0))['preds']\n","                temp = np.exp(temp.detach().cpu().numpy().reshape(-1,1)) - 1\n","                preds_f_delta = np.hstack((preds_f_delta, temp))\n","\n","            preds_f_delta = np.log(1 + preds_f_delta)\n","            val_len = train_p_c.values.shape[1] - TRAIN_N\n","\n","            m2 = np.sqrt(mean_squared_error(np.log(1 + train_p_f_raw.values[:, TRAIN_N:TRAIN_N+val_len]).flatten(), \\\n","                                            preds_f_delta[:, TRAIN_N:TRAIN_N+val_len].flatten()))\n","            print(f\"{epoch:2} train_loss {avg_train_loss:<8.4f} val_loss {m2:8.5f} {time.time()-s:<2.2f}\")\n","                \n","            model_f.train()\n","        \n","    model_f.eval()\n","    preds_f_delta = train_p_f.values[:,:TRAIN_N]\n","    \n","    for idx, data in enumerate(test_loader):\n","        X1 = data['x_c'].to(device).float()\n","        temp = model_f(X1, torch.Tensor(preds_f_delta[:,-1]).unsqueeze(0))['preds']\n","        temp = np.exp(temp.detach().cpu().numpy().reshape(-1,1)) - 1\n","        preds_f_delta = np.hstack((preds_f_delta, temp))\n","    preds_f += preds_f_delta / bag_size\n","\n","preds_f_2 = np.log(1 + preds_f)\n","\n","print(\"Done\")\n","\n","#eval1(np.log(1+train_p_f).values, preds_f_2)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["preds_f = np.average([preds_f_1, preds_f_2], axis=0, weights=[1,2])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.metrics import mean_squared_error\n","\n","if False:\n","    val_len = train_p_c.values.shape[1] - TRAIN_N\n","\n","    for i in range(val_len):\n","        d = i + TRAIN_N\n","        m1 = np.sqrt(mean_squared_error(np.log(1 + train_p_c_raw.values[:, d]), preds_c[:, d]))\n","        m2 = np.sqrt(mean_squared_error(np.log(1 + train_p_f_raw.values[:, d]), preds_f[:, d]))\n","        print(f\"{d}: {(m1 + m2)/2:8.5f} [{m1:8.5f} {m2:8.5f}]\")\n","\n","    print()\n","\n","    m1 = np.sqrt(mean_squared_error(np.log(1 + train_p_c_raw.values[:, TRAIN_N:TRAIN_N+val_len]).flatten(), preds_c[:, TRAIN_N:TRAIN_N+val_len].flatten()))\n","    m2 = np.sqrt(mean_squared_error(np.log(1 + train_p_f_raw.values[:, TRAIN_N:TRAIN_N+val_len]).flatten(), preds_f[:, TRAIN_N:TRAIN_N+val_len].flatten()))\n","    print(f\"{(m1 + m2)/2:8.5f} [{m1:8.5f} {m2:8.5f}]\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","plt.style.use(['default'])\n","fig = plt.figure(figsize = (15, 5))\n","\n","#idx = worst_idx\n","#print(AREAS[idx])\n","\n","idx = np.where(AREAS == 'Austria_N/A')[0][0]\n","plt.plot(np.log(1+train_p_c.values[idx]), label=AREAS[idx], color='darkblue')\n","plt.plot(preds_c[idx], linestyle='--', color='darkblue')\n","\n","idx = np.where(AREAS == 'Germany_N/A')[0][0]\n","plt.plot(np.log(1+train_p_c.values[idx]), label=AREAS[idx], color='red')\n","plt.plot(preds_c[idx], linestyle='--', color='red')\n","\n","\n","idx = np.where(AREAS == 'China_Hubei')[0][0]\n","plt.plot(np.log(1+train_p_c.values[idx]), label=AREAS[idx], color='grey')\n","plt.plot(preds_c[idx], linestyle='--', color='grey')\n","\n","\n","idx = np.where(AREAS == 'Iran_N/A')[0][0]\n","plt.plot(np.log(1+train_p_c.values[idx]), label=AREAS[idx], color='green')\n","plt.plot(preds_c[idx], linestyle='--', color='green')\n","\n","\n","idx = np.where(AREAS == 'Japan_N/A')[0][0]\n","plt.plot(np.log(1+train_p_c.values[idx]), label=AREAS[idx], color='purple')\n","plt.plot(preds_c[idx], linestyle='--', color='purple')\n","\n","\n","idx = np.where(AREAS == 'Brazil_N/A')[0][0]\n","plt.plot(np.log(1+train_p_c.values[idx]), label=AREAS[idx], color='black')\n","plt.plot(preds_c[idx], linestyle='--', color='black')\n","\n","\n","idx = np.where(AREAS == 'Denmark_N/A')[0][0]\n","plt.plot(np.log(1+train_p_c.values[idx]), label=AREAS[idx], color='yellow')\n","plt.plot(preds_c[idx], linestyle='--', color='yellow')\n","\n","idx = np.where(AREAS == 'Italy_N/A')[0][0]\n","plt.plot(np.log(1+train_p_c.values[idx]), label=AREAS[idx], color='blue')\n","plt.plot(preds_c[idx], linestyle='--', color='blue')\n","\n","\n","plt.legend()\n","# plt.show()\n","plt.clf()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","plt.style.use(['default'])\n","fig = plt.figure(figsize = (15, 5))\n","\n","#idx = worst_idx\n","#print(AREAS[idx])\n","\n","idx = np.where(AREAS == 'Austria_N/A')[0][0]\n","plt.plot(np.log(1+train_p_f.values[idx]), label=AREAS[idx], color='darkblue')\n","plt.plot(preds_f[idx], linestyle='--', color='darkblue')\n","\n","idx = np.where(AREAS == 'Germany_N/A')[0][0]\n","plt.plot(np.log(1+train_p_f.values[idx]), label=AREAS[idx], color='red')\n","plt.plot(preds_f[idx], linestyle='--', color='red')\n","\n","\n","idx = np.where(AREAS == 'China_Hubei')[0][0]\n","plt.plot(np.log(1+train_p_f.values[idx]), label=AREAS[idx], color='grey')\n","plt.plot(preds_f[idx], linestyle='--', color='grey')\n","\n","\n","idx = np.where(AREAS == 'Iran_N/A')[0][0]\n","plt.plot(np.log(1+train_p_f.values[idx]), label=AREAS[idx], color='green')\n","plt.plot(preds_f[idx], linestyle='--', color='green')\n","\n","\n","idx = np.where(AREAS == 'Japan_N/A')[0][0]\n","plt.plot(np.log(1+train_p_f.values[idx]), label=AREAS[idx], color='purple')\n","plt.plot(preds_f[idx], linestyle='--', color='purple')\n","\n","\n","idx = np.where(AREAS == 'Brazil_N/A')[0][0]\n","plt.plot(np.log(1+train_p_f.values[idx]), label=AREAS[idx], color='black')\n","plt.plot(preds_f[idx], linestyle='--', color='black')\n","\n","\n","idx = np.where(AREAS == 'Denmark_N/A')[0][0]\n","plt.plot(np.log(1+train_p_f.values[idx]), label=AREAS[idx], color='yellow')\n","plt.plot(preds_f[idx], linestyle='--', color='yellow')\n","\n","idx = np.where(AREAS == 'Italy_N/A')[0][0]\n","plt.plot(np.log(1+train_p_f.values[idx]), label=AREAS[idx], color='blue')\n","plt.plot(preds_f[idx], linestyle='--', color='blue')\n","\n","plt.legend()\n","plt.clf()\n","# plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","plt.style.use(['default'])\n","fig = plt.figure(figsize = (15, 5))\n","\n","idx = np.random.choice(N_AREAS)\n","print(AREAS[idx])\n","\n","plt.plot(np.log(1+train_p_c.values[idx]), label=AREAS[idx], color='darkblue')\n","plt.plot(preds_c[idx], linestyle='--', color='darkblue')\n","\n","# plt.show()\n","plt.clf()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["EU_COUNTRIES = ['Austria', 'Italy', 'Belgium', 'Latvia', 'Bulgaria', 'Lithuania', 'Croatia', 'Luxembourg', 'Cyprus', 'Malta', 'Czechia', \n","                'Netherlands', 'Denmark', 'Poland', 'Estonia', 'Portugal', 'Finland', 'Romania', 'France', 'Slovakia', 'Germany', 'Slovenia', \n","                'Greece', 'Spain', 'Hungary', 'Sweden', 'Ireland']\n","EUROPE_OTHER = ['Albania', 'Andorra', 'Bosnia and Herzegovina', 'Liechtenstein', 'Monaco', 'Montenegro', 'North Macedonia',\n","                'Norway', 'San Marino', 'Serbia', 'Switzerland', 'Turkey', 'United Kingdom']\n","AFRICA = ['Algeria', 'Burkina Faso', 'Cameroon', 'Congo (Kinshasa)', \"Cote d'Ivoire\", 'Egypt', 'Ghana', 'Kenya', 'Madagascar',\n","                'Morocco', 'Nigeria', 'Rwanda', 'Senegal', 'South Africa', 'Togo', 'Tunisia', 'Uganda', 'Zambia']\n","NORTH_AMERICA = ['US', 'Canada', 'Mexico']\n","SOUTH_AMERICA = ['Argentina', 'Bolivia', 'Brazil', 'Chile', 'Colombia', 'Ecuador', 'Paraguay', 'Peru', 'Uruguay', 'Venezuela']\n","MIDDLE_EAST = ['Afghanistan', 'Bahrain', 'Iran', 'Iraq', 'Israel', 'Jordan', 'Kuwait', 'Lebanon', 'Oman', 'Qatar', 'Saudi Arabia', 'United Arab Emirates']\n","ASIA = ['Bangladesh', 'Brunei', 'Cambodia', 'India', 'Indonesia', 'Japan', 'Kazakhstan', 'Korea, South', 'Kyrgyzstan', 'Malaysia',\n","                'Pakistan', 'Singapore', 'Sri Lanka', 'Taiwan*', 'Thailand', 'Uzbekistan', 'Vietnam']"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","def plt1(ar, ar2, ax, col='darkblue', linew=0.2):\n","    ax.plot(ar2, linestyle='--', linewidth=linew/2, color=col)\n","    ax.plot(np.log(1+ar), linewidth=linew, color=col)\n","\n","plt.style.use(['default'])\n","fig, axs = plt.subplots(3, 2, figsize=(18, 15), sharey=True)\n","\n","X = train_p_c.values\n","#X = train_p_f.values\n","\n","for ar in range(X.shape[0]):\n","    \n","    temp = X[ar]\n","    temp2 = preds_c[ar]\n","    if 'China' in AREAS[ar]:\n","        plt1(temp, temp2, axs[0,0])\n","    elif AREAS[ar].split('_')[0] in NORTH_AMERICA:\n","        plt1(temp, temp2, axs[0,1])\n","    elif AREAS[ar].split('_')[0] in EU_COUNTRIES + EUROPE_OTHER:\n","        plt1(temp, temp2, axs[1,0])\n","    elif AREAS[ar].split('_')[0] in SOUTH_AMERICA + AFRICA:\n","        plt1(temp, temp2, axs[1,1])\n","    elif AREAS[ar].split('_')[0] in MIDDLE_EAST + ASIA:\n","        plt1(temp, temp2, axs[2,0])\n","    else:\n","        plt1(temp, temp2, axs[2,1])\n","\n","print(\"Confirmed Cases\")\n","axs[0,0].set_title('China')\n","axs[0,1].set_title('North America')\n","axs[1,0].set_title('Europe')\n","axs[1,1].set_title('Africa + South America')\n","axs[2,0].set_title('Asia + Middle East')\n","axs[2,1].set_title('Other')\n","plt.clf()\n","# plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","def plt1(ar, ar2, ax, col='darkblue', linew=0.2):\n","    ax.plot(ar2, linestyle='--', linewidth=linew/2, color=col)\n","    ax.plot(np.log(1+ar), linewidth=linew, color=col)\n","\n","plt.style.use(['default'])\n","fig, axs = plt.subplots(3, 2, figsize=(18, 15), sharey=True)\n","\n","#X = train_p_c.values\n","X = train_p_f.values\n","\n","for ar in range(X.shape[0]):\n","    \n","    temp = X[ar]\n","    temp2 = preds_f[ar]\n","    if 'China' in AREAS[ar]:\n","        plt1(temp, temp2, axs[0,0])\n","    elif AREAS[ar].split('_')[0] in NORTH_AMERICA:\n","        plt1(temp, temp2, axs[0,1])\n","    elif AREAS[ar].split('_')[0] in EU_COUNTRIES + EUROPE_OTHER:\n","        plt1(temp, temp2, axs[1,0])\n","    elif AREAS[ar].split('_')[0] in SOUTH_AMERICA + AFRICA:\n","        plt1(temp, temp2, axs[1,1])\n","    elif AREAS[ar].split('_')[0] in MIDDLE_EAST + ASIA:\n","        plt1(temp, temp2, axs[2,0])\n","    else:\n","        plt1(temp, temp2, axs[2,1])\n","\n","print(\"Fatalities\")\n","axs[0,0].set_title('China')\n","axs[0,1].set_title('North America')\n","axs[1,0].set_title('Europe')\n","axs[1,1].set_title('Africa + South America')\n","axs[2,0].set_title('Asia + Middle East')\n","axs[2,1].set_title('Other')\n","# plt.show()\n","plt.clf()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","temp = pd.DataFrame(np.clip(np.exp(preds_c) - 1, 0, None))\n","temp['Area'] = AREAS\n","temp = temp.melt(id_vars='Area', var_name='days', value_name=\"ConfirmedCases\")\n","\n","test = test_orig.merge(temp, how='left', left_on=['Area', 'days'], right_on=['Area', 'days'])\n","\n","temp = pd.DataFrame(np.clip(np.exp(preds_f) - 1, 0, None))\n","temp['Area'] = AREAS\n","temp = temp.melt(id_vars='Area', var_name='days', value_name=\"Fatalities\")\n","\n","test = test.merge(temp, how='left', left_on=['Area', 'days'], right_on=['Area', 'days'])\n","test.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# test.to_csv(\"submission.csv\", index=False, columns=[\"ForecastId\", \"ConfirmedCases\", \"Fatalities\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["test.days.nunique()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for i, rec in test.groupby('Area').last().sort_values(\"ConfirmedCases\", ascending=False).iterrows():\n","    print(f\"{rec['ConfirmedCases']:10.1f} {rec['Fatalities']:10.1f}  {rec['Country_Region']}, {rec['Province_State']}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(f\"{test.groupby('Area')['ConfirmedCases'].last().sum():10.1f}\")\n","print(f\"{test.groupby('Area')['Fatalities'].last().sum():10.1f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["test_p_c = test.pivot(index='Area', columns='days', values='ConfirmedCases').sort_index().values\n","test_p_f = test.pivot(index='Area', columns='days', values='Fatalities').sort_index().values\n","dates = test.Date.dt.strftime('%d.%m.%Y').unique()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(\"Confirmed Cases\")\n","for i in [7,14,21,28,35,42]:\n","    print(f'week{i//7-1}  ', dates[i],  f'   {round(test_p_c[:,i].sum(),0):,}')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(\"Fatalities\")\n","for i in [7,14,21,28,35,42]:\n","    print(f'week{i//7-1}  ', dates[i],  f'   {round(test_p_f[:,i].sum(),0):,}', )"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":1095900,"sourceId":19853,"sourceType":"competition"}],"dockerImageVersionId":29867,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":4}
